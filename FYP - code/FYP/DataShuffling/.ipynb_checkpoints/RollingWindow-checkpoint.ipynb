{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0756a4a",
   "metadata": {},
   "source": [
    "<Strong> Fixed size time-series which we slide in time to predict into future. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cab64e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0504d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../../cryptoData/BTC_15m_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fbc13a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17 04:00:00</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>2.189061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17 04:15:00</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4270.41</td>\n",
       "      <td>4261.32</td>\n",
       "      <td>4261.45</td>\n",
       "      <td>9.119865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-17 04:30:00</td>\n",
       "      <td>4280.00</td>\n",
       "      <td>4310.07</td>\n",
       "      <td>4267.99</td>\n",
       "      <td>4310.07</td>\n",
       "      <td>21.923552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-17 04:45:00</td>\n",
       "      <td>4310.07</td>\n",
       "      <td>4313.62</td>\n",
       "      <td>4291.37</td>\n",
       "      <td>4308.83</td>\n",
       "      <td>13.948531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-17 05:00:00</td>\n",
       "      <td>4308.83</td>\n",
       "      <td>4328.69</td>\n",
       "      <td>4304.31</td>\n",
       "      <td>4304.31</td>\n",
       "      <td>5.101153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155486</th>\n",
       "      <td>2022-01-28 14:45:00</td>\n",
       "      <td>36684.11</td>\n",
       "      <td>36828.38</td>\n",
       "      <td>36600.00</td>\n",
       "      <td>36759.65</td>\n",
       "      <td>560.007760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155487</th>\n",
       "      <td>2022-01-28 15:00:00</td>\n",
       "      <td>36759.65</td>\n",
       "      <td>37198.00</td>\n",
       "      <td>36682.24</td>\n",
       "      <td>37149.99</td>\n",
       "      <td>649.317780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155488</th>\n",
       "      <td>2022-01-28 15:15:00</td>\n",
       "      <td>37150.00</td>\n",
       "      <td>37300.00</td>\n",
       "      <td>36925.89</td>\n",
       "      <td>36988.91</td>\n",
       "      <td>1061.113920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155489</th>\n",
       "      <td>2022-01-28 15:30:00</td>\n",
       "      <td>36985.43</td>\n",
       "      <td>37115.32</td>\n",
       "      <td>36874.46</td>\n",
       "      <td>37022.42</td>\n",
       "      <td>452.420950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155490</th>\n",
       "      <td>2022-01-28 15:45:00</td>\n",
       "      <td>37023.86</td>\n",
       "      <td>37271.54</td>\n",
       "      <td>37000.34</td>\n",
       "      <td>37231.02</td>\n",
       "      <td>254.796250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155491 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date      open      high       low     close  \\\n",
       "0       2017-08-17 04:00:00   4261.48   4280.56   4261.48   4261.48   \n",
       "1       2017-08-17 04:15:00   4261.48   4270.41   4261.32   4261.45   \n",
       "2       2017-08-17 04:30:00   4280.00   4310.07   4267.99   4310.07   \n",
       "3       2017-08-17 04:45:00   4310.07   4313.62   4291.37   4308.83   \n",
       "4       2017-08-17 05:00:00   4308.83   4328.69   4304.31   4304.31   \n",
       "...                     ...       ...       ...       ...       ...   \n",
       "155486  2022-01-28 14:45:00  36684.11  36828.38  36600.00  36759.65   \n",
       "155487  2022-01-28 15:00:00  36759.65  37198.00  36682.24  37149.99   \n",
       "155488  2022-01-28 15:15:00  37150.00  37300.00  36925.89  36988.91   \n",
       "155489  2022-01-28 15:30:00  36985.43  37115.32  36874.46  37022.42   \n",
       "155490  2022-01-28 15:45:00  37023.86  37271.54  37000.34  37231.02   \n",
       "\n",
       "             volume  \n",
       "0          2.189061  \n",
       "1          9.119865  \n",
       "2         21.923552  \n",
       "3         13.948531  \n",
       "4          5.101153  \n",
       "...             ...  \n",
       "155486   560.007760  \n",
       "155487   649.317780  \n",
       "155488  1061.113920  \n",
       "155489   452.420950  \n",
       "155490   254.796250  \n",
       "\n",
       "[155491 rows x 6 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7e447544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.26148000e+03 4.28056000e+03 4.26148000e+03 4.26148000e+03\n",
      "  2.18906100e+00]\n",
      " [4.26148000e+03 4.27041000e+03 4.26132000e+03 4.26145000e+03\n",
      "  9.11986500e+00]\n",
      " [4.28000000e+03 4.31007000e+03 4.26799000e+03 4.31007000e+03\n",
      "  2.19235520e+01]\n",
      " ...\n",
      " [3.71500000e+04 3.73000000e+04 3.69258900e+04 3.69889100e+04\n",
      "  1.06111392e+03]\n",
      " [3.69854300e+04 3.71153200e+04 3.68744600e+04 3.70224200e+04\n",
      "  4.52420950e+02]\n",
      " [3.70238600e+04 3.72715400e+04 3.70003400e+04 3.72310200e+04\n",
      "  2.54796250e+02]]\n"
     ]
    }
   ],
   "source": [
    "float_data = df.values[:, 1: ,].astype(float)\n",
    "print(float_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "06a9a1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4261.48  4261.45  4310.07 ... 36988.91 37022.42 37231.02]\n"
     ]
    }
   ],
   "source": [
    "data = float_data[:,3,]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bea70f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef rolling_window(train_data , window_size , predict_future_steps):\\n    while True:\\n    \\n        for i in range (len(train_data) - window_size - predict_future_steps + 1):\\n\\n            split_train = train_data[i:window_size+i]\\n            split_val = train_data[i+window_size:window_size+i+predict_future_steps]\\n\\n            yield split_train , split_val\\n'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def rolling_window(train_data , window_size , predict_future_steps):\n",
    "    while True:\n",
    "    \n",
    "        for i in range (len(train_data) - window_size - predict_future_steps + 1):\n",
    "\n",
    "            split_train = train_data[i:window_size+i]\n",
    "            split_val = train_data[i+window_size:window_size+i+predict_future_steps]\n",
    "\n",
    "            yield split_train , split_val\n",
    "            \n",
    "rolling = rolling_window(subData , 10 , 1)\n",
    "\n",
    "for train , val in rolling:\n",
    "    print(train.shape)\n",
    "    print(val.shape)\n",
    "    break\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "08c275fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData = data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "69943853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fh = np.arange(1, len(subData) + 1)  # we add 1 because the `stop` value is exclusive in `np.arange`\n",
    "fh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ab84e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# slightly modified code from the M4 competition\n",
    "def split_into_train_test(data, in_num, fh):\n",
    "    \"\"\"\n",
    "    Splits the series into train and test sets. Each step takes multiple points as inputs\n",
    "    :param data: an individual TS\n",
    "    :param fh: number of out of sample points\n",
    "    :param in_num: number of input points for the forecast\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train, test = data[:-fh], data[-(fh + in_num):]\n",
    "    x_train, y_train = train[:-1], np.roll(train, -in_num)[:-in_num]\n",
    "    x_test, y_test = test[:-1], np.roll(test, -in_num)[:-in_num]\n",
    "#     x_test, y_test = train[-in_num:], np.roll(test, -in_num)[:-in_num]\n",
    "\n",
    "    # reshape input to be [samples, time steps, features] (N-NF samples, 1 time step, 1 feature)\n",
    "    x_train = np.reshape(x_train, (-1, 1))\n",
    "    x_test = np.reshape(x_test, (-1, 1))\n",
    "    temp_test = np.roll(x_test, -1)\n",
    "    temp_train = np.roll(x_train, -1)\n",
    "    for x in range(1, in_num):\n",
    "        x_train = np.concatenate((x_train[:-1], temp_train[:-1]), 1)\n",
    "        x_test = np.concatenate((x_test[:-1], temp_test[:-1]), 1)\n",
    "        temp_test = np.roll(temp_test, -1)[:-1]\n",
    "        temp_train = np.roll(temp_train, -1)[:-1]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a761803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can split the actual values of the time series\n",
    "x_train, y_train, x_test, y_test = split_into_train_test(subData, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0492581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4261.48 4261.45 4310.07 4308.83 4304.31 4320.   4291.37 4315.32 4330.\n",
      "  4311.02]\n",
      " [4261.45 4310.07 4308.83 4304.31 4320.   4291.37 4315.32 4330.   4311.02\n",
      "  4345.45]\n",
      " [4310.07 4308.83 4304.31 4320.   4291.37 4315.32 4330.   4311.02 4345.45\n",
      "  4324.35]\n",
      " [4308.83 4304.31 4320.   4291.37 4315.32 4330.   4311.02 4345.45 4324.35\n",
      "  4316.62]\n",
      " [4304.31 4320.   4291.37 4315.32 4330.   4311.02 4345.45 4324.35 4316.62\n",
      "  4291.38]\n",
      " [4320.   4291.37 4315.32 4330.   4311.02 4345.45 4324.35 4316.62 4291.38\n",
      "  4300.  ]\n",
      " [4291.37 4315.32 4330.   4311.02 4345.45 4324.35 4316.62 4291.38 4300.\n",
      "  4349.99]\n",
      " [4315.32 4330.   4311.02 4345.45 4324.35 4316.62 4291.38 4300.   4349.99\n",
      "  4360.71]\n",
      " [4330.   4311.02 4345.45 4324.35 4316.62 4291.38 4300.   4349.99 4360.71\n",
      "  4360.7 ]\n",
      " [4311.02 4345.45 4324.35 4316.62 4291.38 4300.   4349.99 4360.71 4360.7\n",
      "  4360.69]\n",
      " [4345.45 4324.35 4316.62 4291.38 4300.   4349.99 4360.71 4360.7  4360.69\n",
      "  4360.69]\n",
      " [4324.35 4316.62 4291.38 4300.   4349.99 4360.71 4360.7  4360.69 4360.69\n",
      "  4360.  ]\n",
      " [4316.62 4291.38 4300.   4349.99 4360.71 4360.7  4360.69 4360.69 4360.\n",
      "  4360.  ]\n",
      " [4291.38 4300.   4349.99 4360.71 4360.7  4360.69 4360.69 4360.   4360.\n",
      "  4436.51]\n",
      " [4300.   4349.99 4360.71 4360.7  4360.69 4360.69 4360.   4360.   4436.51\n",
      "  4444.  ]\n",
      " [4349.99 4360.71 4360.7  4360.69 4360.69 4360.   4360.   4436.51 4444.\n",
      "  4400.  ]\n",
      " [4360.71 4360.7  4360.69 4360.69 4360.   4360.   4436.51 4444.   4400.\n",
      "  4440.  ]\n",
      " [4360.7  4360.69 4360.69 4360.   4360.   4436.51 4444.   4400.   4440.\n",
      "  4415.  ]\n",
      " [4360.69 4360.69 4360.   4360.   4436.51 4444.   4400.   4440.   4415.\n",
      "  4460.  ]\n",
      " [4360.69 4360.   4360.   4436.51 4444.   4400.   4440.   4415.   4460.\n",
      "  4474.8 ]\n",
      " [4360.   4360.   4436.51 4444.   4400.   4440.   4415.   4460.   4474.8\n",
      "  4485.39]\n",
      " [4360.   4436.51 4444.   4400.   4440.   4415.   4460.   4474.8  4485.39\n",
      "  4469.93]\n",
      " [4436.51 4444.   4400.   4440.   4415.   4460.   4474.8  4485.39 4469.93\n",
      "  4427.3 ]\n",
      " [4444.   4400.   4440.   4415.   4460.   4474.8  4485.39 4469.93 4427.3\n",
      "  4441.87]\n",
      " [4400.   4440.   4415.   4460.   4474.8  4485.39 4469.93 4427.3  4441.87\n",
      "  4418.12]\n",
      " [4440.   4415.   4460.   4474.8  4485.39 4469.93 4427.3  4441.87 4418.12\n",
      "  4431.13]\n",
      " [4415.   4460.   4474.8  4485.39 4469.93 4427.3  4441.87 4418.12 4431.13\n",
      "  4411.  ]\n",
      " [4460.   4474.8  4485.39 4469.93 4427.3  4441.87 4418.12 4431.13 4411.\n",
      "  4445.88]\n",
      " [4474.8  4485.39 4469.93 4427.3  4441.87 4418.12 4431.13 4411.   4445.88\n",
      "  4440.  ]\n",
      " [4485.39 4469.93 4427.3  4441.87 4418.12 4431.13 4411.   4445.88 4440.\n",
      "  4445.  ]\n",
      " [4469.93 4427.3  4441.87 4418.12 4431.13 4411.   4445.88 4440.   4445.\n",
      "  4459.  ]\n",
      " [4427.3  4441.87 4418.12 4431.13 4411.   4445.88 4440.   4445.   4459.\n",
      "  4452.71]\n",
      " [4441.87 4418.12 4431.13 4411.   4445.88 4440.   4445.   4459.   4452.71\n",
      "  4467.81]\n",
      " [4418.12 4431.13 4411.   4445.88 4440.   4445.   4459.   4452.71 4467.81\n",
      "  4477.53]\n",
      " [4431.13 4411.   4445.88 4440.   4445.   4459.   4452.71 4467.81 4477.53\n",
      "  4470.82]\n",
      " [4411.   4445.88 4440.   4445.   4459.   4452.71 4467.81 4477.53 4470.82\n",
      "  4460.  ]\n",
      " [4445.88 4440.   4445.   4459.   4452.71 4467.81 4477.53 4470.82 4460.\n",
      "  4432.2 ]\n",
      " [4440.   4445.   4459.   4452.71 4467.81 4477.53 4470.82 4460.   4432.2\n",
      "  4396.47]\n",
      " [4445.   4459.   4452.71 4467.81 4477.53 4470.82 4460.   4432.2  4396.47\n",
      "  4352.34]\n",
      " [4459.   4452.71 4467.81 4477.53 4470.82 4460.   4432.2  4396.47 4352.34\n",
      "  4307.17]\n",
      " [4452.71 4467.81 4477.53 4470.82 4460.   4432.2  4396.47 4352.34 4307.17\n",
      "  4290.17]\n",
      " [4467.81 4477.53 4470.82 4460.   4432.2  4396.47 4352.34 4307.17 4290.17\n",
      "  4300.29]\n",
      " [4477.53 4470.82 4460.   4432.2  4396.47 4352.34 4307.17 4290.17 4300.29\n",
      "  4354.18]\n",
      " [4470.82 4460.   4432.2  4396.47 4352.34 4307.17 4290.17 4300.29 4354.18\n",
      "  4341.31]\n",
      " [4460.   4432.2  4396.47 4352.34 4307.17 4290.17 4300.29 4354.18 4341.31\n",
      "  4335.28]\n",
      " [4432.2  4396.47 4352.34 4307.17 4290.17 4300.29 4354.18 4341.31 4335.28\n",
      "  4328.15]\n",
      " [4396.47 4352.34 4307.17 4290.17 4300.29 4354.18 4341.31 4335.28 4328.15\n",
      "  4289.24]\n",
      " [4352.34 4307.17 4290.17 4300.29 4354.18 4341.31 4335.28 4328.15 4289.24\n",
      "  4282.43]\n",
      " [4307.17 4290.17 4300.29 4354.18 4341.31 4335.28 4328.15 4289.24 4282.43\n",
      "  4287.69]\n",
      " [4290.17 4300.29 4354.18 4341.31 4335.28 4328.15 4289.24 4282.43 4287.69\n",
      "  4237.85]\n",
      " [4300.29 4354.18 4341.31 4335.28 4328.15 4289.24 4282.43 4287.69 4237.85\n",
      "  4256.97]\n",
      " [4354.18 4341.31 4335.28 4328.15 4289.24 4282.43 4287.69 4237.85 4256.97\n",
      "  4281.87]\n",
      " [4341.31 4335.28 4328.15 4289.24 4282.43 4287.69 4237.85 4256.97 4281.87\n",
      "  4287.61]\n",
      " [4335.28 4328.15 4289.24 4282.43 4287.69 4237.85 4256.97 4281.87 4287.61\n",
      "  4327.25]\n",
      " [4328.15 4289.24 4282.43 4287.69 4237.85 4256.97 4281.87 4287.61 4327.25\n",
      "  4325.23]\n",
      " [4289.24 4282.43 4287.69 4237.85 4256.97 4281.87 4287.61 4327.25 4325.23\n",
      "  4278.05]\n",
      " [4282.43 4287.69 4237.85 4256.97 4281.87 4287.61 4327.25 4325.23 4278.05\n",
      "  4273.16]\n",
      " [4287.69 4237.85 4256.97 4281.87 4287.61 4327.25 4325.23 4278.05 4273.16\n",
      "  4305.  ]\n",
      " [4237.85 4256.97 4281.87 4287.61 4327.25 4325.23 4278.05 4273.16 4305.\n",
      "  4346.74]\n",
      " [4256.97 4281.87 4287.61 4327.25 4325.23 4278.05 4273.16 4305.   4346.74\n",
      "  4367.93]\n",
      " [4281.87 4287.61 4327.25 4325.23 4278.05 4273.16 4305.   4346.74 4367.93\n",
      "  4349.33]\n",
      " [4287.61 4327.25 4325.23 4278.05 4273.16 4305.   4346.74 4367.93 4349.33\n",
      "  4354.35]\n",
      " [4327.25 4325.23 4278.05 4273.16 4305.   4346.74 4367.93 4349.33 4354.35\n",
      "  4333.55]\n",
      " [4325.23 4278.05 4273.16 4305.   4346.74 4367.93 4349.33 4354.35 4333.55\n",
      "  4334.32]\n",
      " [4278.05 4273.16 4305.   4346.74 4367.93 4349.33 4354.35 4333.55 4334.32\n",
      "  4326.29]\n",
      " [4273.16 4305.   4346.74 4367.93 4349.33 4354.35 4333.55 4334.32 4326.29\n",
      "  4352.34]\n",
      " [4305.   4346.74 4367.93 4349.33 4354.35 4333.55 4334.32 4326.29 4352.34\n",
      "  4336.8 ]\n",
      " [4346.74 4367.93 4349.33 4354.35 4333.55 4334.32 4326.29 4352.34 4336.8\n",
      "  4323.31]\n",
      " [4367.93 4349.33 4354.35 4333.55 4334.32 4326.29 4352.34 4336.8  4323.31\n",
      "  4327.89]\n",
      " [4349.33 4354.35 4333.55 4334.32 4326.29 4352.34 4336.8  4323.31 4327.89\n",
      "  4328.25]\n",
      " [4354.35 4333.55 4334.32 4326.29 4352.34 4336.8  4323.31 4327.89 4328.25\n",
      "  4285.08]\n",
      " [4333.55 4334.32 4326.29 4352.34 4336.8  4323.31 4327.89 4328.25 4285.08\n",
      "  4305.76]\n",
      " [4334.32 4326.29 4352.34 4336.8  4323.31 4327.89 4328.25 4285.08 4305.76\n",
      "  4292.11]\n",
      " [4326.29 4352.34 4336.8  4323.31 4327.89 4328.25 4285.08 4305.76 4292.11\n",
      "  4302.15]\n",
      " [4352.34 4336.8  4323.31 4327.89 4328.25 4285.08 4305.76 4292.11 4302.15\n",
      "  4286.53]\n",
      " [4336.8  4323.31 4327.89 4328.25 4285.08 4305.76 4292.11 4302.15 4286.53\n",
      "  4251.4 ]\n",
      " [4323.31 4327.89 4328.25 4285.08 4305.76 4292.11 4302.15 4286.53 4251.4\n",
      "  4214.97]\n",
      " [4327.89 4328.25 4285.08 4305.76 4292.11 4302.15 4286.53 4251.4  4214.97\n",
      "  4231.61]\n",
      " [4328.25 4285.08 4305.76 4292.11 4302.15 4286.53 4251.4  4214.97 4231.61\n",
      "  4243.59]\n",
      " [4285.08 4305.76 4292.11 4302.15 4286.53 4251.4  4214.97 4231.61 4243.59\n",
      "  4286.53]\n",
      " [4305.76 4292.11 4302.15 4286.53 4251.4  4214.97 4231.61 4243.59 4286.53\n",
      "  4278.05]\n",
      " [4292.11 4302.15 4286.53 4251.4  4214.97 4231.61 4243.59 4286.53 4278.05\n",
      "  4252.95]\n",
      " [4302.15 4286.53 4251.4  4214.97 4231.61 4243.59 4286.53 4278.05 4252.95\n",
      "  4267.59]\n",
      " [4286.53 4251.4  4214.97 4231.61 4243.59 4286.53 4278.05 4252.95 4267.59\n",
      "  4308.7 ]\n",
      " [4251.4  4214.97 4231.61 4243.59 4286.53 4278.05 4252.95 4267.59 4308.7\n",
      "  4244.77]\n",
      " [4214.97 4231.61 4243.59 4286.53 4278.05 4252.95 4267.59 4308.7  4244.77\n",
      "  4277.81]\n",
      " [4231.61 4243.59 4286.53 4278.05 4252.95 4267.59 4308.7  4244.77 4277.81\n",
      "  4292.39]\n",
      " [4243.59 4286.53 4278.05 4252.95 4267.59 4308.7  4244.77 4277.81 4292.39\n",
      "  4252.01]\n",
      " [4286.53 4278.05 4252.95 4267.59 4308.7  4244.77 4277.81 4292.39 4252.01\n",
      "  4245.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "adae6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0e0f77dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(), loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7adb93b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 12)                132       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245\n",
      "Trainable params: 245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d5eedcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 6ms/step - loss: 2159.1406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13c45bd00>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84718d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252f025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e01f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9dc27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
