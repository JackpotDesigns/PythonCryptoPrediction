{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2d07cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.layers import LSTM , Dense , Dropout , GRU , Concatenate , Input , Conv1D , InputLayer\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f2813",
   "metadata": {},
   "source": [
    "<Strong> PART 1 : Pulling Data , Grabbing Closing Price , Splitting , Scaling. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96dce357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc = pd.read_csv(\"../../../cryptoData/BTC_1h_data.csv\")\n",
    "df_xrp = pd.read_csv(\"../../../cryptoData/XRP_1h_data.csv\")\n",
    "df_eth = pd.read_csv(\"../../../cryptoData/ETH_1h_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84b86bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing everything but the closing price\n",
    "btc_data = df_btc.values[:, 4 ,].astype(float)\n",
    "eth_data = df_eth.values[:, 4 ,].astype(float)\n",
    "xrp_data = df_xrp.values[:, 4 ,].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2fd8fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting off training , validation ,  test sets , 70% , 20% , 10%\n",
    "\n",
    "def splitting_train_test(data , percTrain , percVal):\n",
    "    onePercent = len(data) // 100\n",
    "    \n",
    "    numberTraining = onePercent * percTrain\n",
    "    numberValidation = onePercent * percVal\n",
    "    \n",
    "    trainingData = data[:numberTraining]\n",
    "    validationData = data[numberTraining : numberTraining + numberValidation]\n",
    "    testData = data[numberTraining + numberValidation:] \n",
    "    \n",
    "    return trainingData.reshape(-1,1) , validationData.reshape(-1,1) , testData.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68f05b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27440, 1), (7840, 1), (3941, 1))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshaping the data so we can use min-max scaler on it\n",
    "\n",
    "btc_train , btc_val ,  btc_test = splitting_train_test(btc_data , 70 , 20 )\n",
    "eth_train , eth_val , eth_test = splitting_train_test(eth_data , 70 , 20 )\n",
    "xrp_train , xrp_val , xrp_test = splitting_train_test(xrp_data , 70 , 20 )\n",
    "\n",
    "(btc_train.shape , btc_val.shape , btc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2947b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_data(train , validation , test):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train)\n",
    "    \n",
    "    return scaler.transform(train) , scaler.transform(validation) , scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b601cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data after we split to avoid leakage, transforming validation and test from training set for the same reason.\n",
    "\n",
    "scaled_train_btc , scaled_val_btc , scaled_test_btc = scaling_data(btc_train , btc_val , btc_test)\n",
    "scaled_train_eth , scaled_val_eth , scaled_test_eth = scaling_data(eth_train , eth_val , eth_test)\n",
    "scaled_train_xrp , scaled_val_xrp , scaled_test_xrp = scaling_data(xrp_train , xrp_val , xrp_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1afda71",
   "metadata": {},
   "source": [
    "<Strong> PART 2 : Rolling Window Format , . </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1099c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting window size to 12\n",
    "ds = tf.keras.preprocessing.timeseries_dataset_from_array(btc_data, btc_data[12:], 12, batch_size=1)\n",
    "\n",
    "data = np.array([])\n",
    "labels = np.array([])\n",
    "\n",
    "for inputs, targets in ds:\n",
    "    np.append(data, np.array(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13fcf054",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cv/9wyhthmx21d7ylr5zx17lfmr0000gn/T/ipykernel_6019/804734267.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mWindowGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Store the raw data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cv/9wyhthmx21d7ylr5zx17lfmr0000gn/T/ipykernel_6019/804734267.py\u001b[0m in \u001b[0;36mWindowGenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mWindowGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Store the raw data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "class WindowGenerator():\n",
    "    \n",
    "    def __init__(self, input_width, label_width, shift, train_df=train_df, val_df=val_df, test_df=test_df, label_columns=None):\n",
    "    # Store the raw data.\n",
    "    \n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "        self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7041e648",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'window_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cv/9wyhthmx21d7ylr5zx17lfmr0000gn/T/ipykernel_6019/2096710569.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwindow_length\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#From deep learning in python -- better to use recurrent dropout so error propergates correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'window_length' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (window_length , features) )\n",
    "\n",
    "#From deep learning in python -- better to use recurrent dropout so error propergates correctly\n",
    "x = LSTM(30 , dropout = 0.5 , recurrent_dropout = 0.5 , return_sequences = True)(inputs)\n",
    "x = LSTM(50 , activation = 'relu')(x)\n",
    "x = Dense(16)(x)\n",
    "\n",
    "y = GRU(30 , dropout = 0.5 , recurrent_dropout = 0.5 , activation='relu' , input_shape=(window_length , features))(inputs)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Dense(16)(y)\n",
    "\n",
    "final = Concatenate()([x,y])\n",
    "final = Dense(1)(final)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs= final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4165b396",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cv/9wyhthmx21d7ylr5zx17lfmr0000gn/T/ipykernel_6019/417229082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0myou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moii\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a7321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
