{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56f0a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop , Adam\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error , mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.layers import LSTM , Dense , Dropout , GRU , Concatenate , Input , Conv1D , InputLayer\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947652df",
   "metadata": {},
   "source": [
    "<Strong> Grabbing the data from stored files (originally pulled from Binance) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe63049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eth = pd.read_csv(\"ETH_1h_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63c93ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17 04:00:00.000</td>\n",
       "      <td>301.13</td>\n",
       "      <td>302.57</td>\n",
       "      <td>298.00</td>\n",
       "      <td>301.61</td>\n",
       "      <td>125.66877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17 05:00:00.000</td>\n",
       "      <td>301.61</td>\n",
       "      <td>303.28</td>\n",
       "      <td>300.00</td>\n",
       "      <td>303.10</td>\n",
       "      <td>377.67246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-17 06:00:00.000</td>\n",
       "      <td>302.40</td>\n",
       "      <td>304.44</td>\n",
       "      <td>301.90</td>\n",
       "      <td>302.68</td>\n",
       "      <td>303.86672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-17 07:00:00.000</td>\n",
       "      <td>302.68</td>\n",
       "      <td>307.96</td>\n",
       "      <td>302.60</td>\n",
       "      <td>307.96</td>\n",
       "      <td>754.74510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-17 08:00:00.000</td>\n",
       "      <td>307.95</td>\n",
       "      <td>309.97</td>\n",
       "      <td>307.00</td>\n",
       "      <td>308.62</td>\n",
       "      <td>150.75029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39216</th>\n",
       "      <td>2022-02-11 10:00:00</td>\n",
       "      <td>3102.22</td>\n",
       "      <td>3115.98</td>\n",
       "      <td>3075.24</td>\n",
       "      <td>3106.33</td>\n",
       "      <td>12865.43100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39217</th>\n",
       "      <td>2022-02-11 11:00:00</td>\n",
       "      <td>3106.34</td>\n",
       "      <td>3109.86</td>\n",
       "      <td>3083.93</td>\n",
       "      <td>3088.30</td>\n",
       "      <td>7796.24450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39218</th>\n",
       "      <td>2022-02-11 12:00:00</td>\n",
       "      <td>3088.30</td>\n",
       "      <td>3122.00</td>\n",
       "      <td>3079.16</td>\n",
       "      <td>3102.23</td>\n",
       "      <td>13475.38960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39219</th>\n",
       "      <td>2022-02-11 13:00:00</td>\n",
       "      <td>3102.22</td>\n",
       "      <td>3127.00</td>\n",
       "      <td>3095.00</td>\n",
       "      <td>3121.64</td>\n",
       "      <td>13585.96880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39220</th>\n",
       "      <td>2022-02-11 14:00:00</td>\n",
       "      <td>3121.65</td>\n",
       "      <td>3128.20</td>\n",
       "      <td>3104.56</td>\n",
       "      <td>3110.51</td>\n",
       "      <td>5450.64810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39221 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date     open     high      low    close  \\\n",
       "0      2017-08-17 04:00:00.000   301.13   302.57   298.00   301.61   \n",
       "1      2017-08-17 05:00:00.000   301.61   303.28   300.00   303.10   \n",
       "2      2017-08-17 06:00:00.000   302.40   304.44   301.90   302.68   \n",
       "3      2017-08-17 07:00:00.000   302.68   307.96   302.60   307.96   \n",
       "4      2017-08-17 08:00:00.000   307.95   309.97   307.00   308.62   \n",
       "...                        ...      ...      ...      ...      ...   \n",
       "39216      2022-02-11 10:00:00  3102.22  3115.98  3075.24  3106.33   \n",
       "39217      2022-02-11 11:00:00  3106.34  3109.86  3083.93  3088.30   \n",
       "39218      2022-02-11 12:00:00  3088.30  3122.00  3079.16  3102.23   \n",
       "39219      2022-02-11 13:00:00  3102.22  3127.00  3095.00  3121.64   \n",
       "39220      2022-02-11 14:00:00  3121.65  3128.20  3104.56  3110.51   \n",
       "\n",
       "            volume  \n",
       "0        125.66877  \n",
       "1        377.67246  \n",
       "2        303.86672  \n",
       "3        754.74510  \n",
       "4        150.75029  \n",
       "...            ...  \n",
       "39216  12865.43100  \n",
       "39217   7796.24450  \n",
       "39218  13475.38960  \n",
       "39219  13585.96880  \n",
       "39220   5450.64810  \n",
       "\n",
       "[39221 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bde6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_headers = df_eth.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68634f1",
   "metadata": {},
   "source": [
    "<Strong> Grabbing the closing price (univariate) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "512d2ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39221"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing everything but the closing price\n",
    "eth_data = df_eth.values[:, 4 ,].astype(float)\n",
    "\n",
    "len(eth_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff079aa",
   "metadata": {},
   "source": [
    "<Strong> Scaling the data  </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81b6f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "percTrain = 70\n",
    "percVal = 20\n",
    "\n",
    "onePercent = len(eth_data) // 100\n",
    "numberTraining = onePercent * percTrain\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "reshaped_data = eth_data.reshape(-1,1)\n",
    "\n",
    "#Just scaling on training data otherwise it would be leakage\n",
    "scaler.fit(reshaped_data[:numberTraining])\n",
    "scaled_eth = scaler.transform(reshaped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a4ccd",
   "metadata": {},
   "source": [
    "<Strong> Creating Matrix in Sliding window form <Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddf6b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(elements, window_size):\n",
    "    \n",
    "    data = [] \n",
    "    targets = []\n",
    "    \n",
    "    if len(elements) <= window_size:\n",
    "        return elements\n",
    "    \n",
    "    for i in range(len(elements) - window_size ):\n",
    "        \n",
    "        data.append(elements[i:i+window_size])\n",
    "        targets.append(elements[i+window_size])\n",
    "        \n",
    "    return np.array(data) , np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ddaa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 24\n",
    "features = 1\n",
    "\n",
    "\n",
    "sliding_winda_eth = sliding_window(scaled_eth , window_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fef525",
   "metadata": {},
   "source": [
    "<Strong> Splitting the data after we create Sliding Window matrix (more data) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1731b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data after creating the sliding window data\n",
    "\n",
    "def splitting_train_test(data):\n",
    "        \n",
    "    onePercent = len(data[1]) // 100\n",
    "    \n",
    "    numberTraining = onePercent * percTrain\n",
    "    numberValidation = onePercent * percVal\n",
    "    \n",
    "    trainingData = data[0][:numberTraining] , data[1][:numberTraining]\n",
    "    validationData = data[0][numberTraining : numberTraining + numberValidation] , data[1][numberTraining : numberTraining + numberValidation]\n",
    "    testData = data[0][numberTraining + numberValidation:] , data[1][numberTraining + numberValidation:] \n",
    "    \n",
    "    #Returning tuples of (sliding-window , target_values)\n",
    "    return trainingData , validationData , testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05f85f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27370, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshaping the data so we can use min-max a\n",
    "eth_train , eth_val , eth_test = splitting_train_test(sliding_winda_eth)\n",
    "\n",
    "print(eth_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a800f1",
   "metadata": {},
   "source": [
    "<Strong> Creating the model </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "844b2b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 22:50:47.308069: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 24, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 24, 30)       3840        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 24, 30)       0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 30)           2970        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 50)           16200       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 30)           0           ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          6528        ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          3968        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256)          0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            257         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33,763\n",
      "Trainable params: 33,763\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (window_length , features) )\n",
    "\n",
    "#activation=layers.LeakyReLU(alpha=0.01)\n",
    "#From deep learning in python -- better to use recurrent dropout so error propergates correctly\n",
    "x = LSTM(30 , return_sequences = True )(inputs)\n",
    "x = Dropout(0.03)(x) \n",
    "x = LSTM(50)(x)\n",
    "x = Dense(128 , activation=layers.LeakyReLU(alpha=0.01))(x)\n",
    "\n",
    "y = GRU(30,input_shape=(window_length , features))(inputs)\n",
    "y = Dropout(0.03)(y)\n",
    "y = Dense(128 , activation=layers.LeakyReLU(alpha=0.01))(y)\n",
    "\n",
    "final = Concatenate()([x,y])\n",
    "final = Dense(1)(final)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs= final)\n",
    "\n",
    "model.summary()\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e8d01a",
   "metadata": {},
   "source": [
    "<Strong> Compiling the model </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb0a256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(0.008)\n",
    "model.compile(optimizer=opt , loss = 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cee5682",
   "metadata": {},
   "source": [
    "<Strong> Creating a callback to avail of early stopping </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc75089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor = 'val_loss' , patience = 30 , mode = 'min' , verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641f8de",
   "metadata": {},
   "source": [
    "<Strong> Training the model and storing the epoch where training stopped </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e1f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "54/54 [==============================] - 9s 98ms/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 5s 87ms/step - loss: 9.7181e-05 - val_loss: 0.0059\n",
      "Epoch 3/300\n",
      "40/54 [=====================>........] - ETA: 1s - loss: 7.5055e-05"
     ]
    }
   ],
   "source": [
    "#Validation set needs to be in a tuple with x , y\n",
    "history = model.fit(eth_train[0] , eth_train[1] , validation_data = eth_val  , batch_size = 512  , epochs =300 , verbose = 1 , callbacks = [earlyStopping] )\n",
    "num_epochs = earlyStopping.stopped_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429869ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.ylim([0,0.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562b1eed",
   "metadata": {},
   "source": [
    "<Strong> Testing on the validation data once again , hyper-parameter adjustment. <Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predict = model.predict(eth_val[0])\n",
    "validation_actual = eth_val[1]\n",
    "\n",
    "mean_squared_error(validation_actual , validation_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04397524",
   "metadata": {},
   "source": [
    "<Strong> Combining the train and validation set when perfected hyper-parameters and training on fresh model. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_val = np.concatenate([eth_train[0] , eth_val[0]] )\n",
    "train_and_val_targets = np.concatenate([eth_train[1] , eth_val[1] ])\n",
    "\n",
    "freshModel = tf.keras.Model(inputs=inputs, outputs= final)\n",
    "freshModel.compile(optimizer=opt , loss = 'mse')\n",
    "\n",
    "final = freshModel.fit(train_and_val , train_and_val_targets , batch_size = 512  , epochs = num_epochs , verbose = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8f5321",
   "metadata": {},
   "source": [
    "<Strong> Finally testing on test set and grabbing evaluation metrics </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac71a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = freshModel.predict(eth_test[0])\n",
    "\n",
    "test_actual = eth_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f959fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(test_actual , test_predict))\n",
    "print(mean_absolute_percentage_error(test_actual , test_predict))\n",
    "print(mean_squared_error(test_actual , test_predict , squared = False))\n",
    "print(mean_squared_error(test_actual , test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ca691",
   "metadata": {},
   "source": [
    "<Strong> For Predicting more than 1 day in the future - Test Set. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96f06ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steps_in_future(hours_in_future , data):\n",
    "    \n",
    "    #All the hours_in_future time predictions\n",
    "    predictions = []\n",
    "    \n",
    "    # Have to cut off the (hours_in_future - 1) off the test set to avoid out of bounds error\n",
    "    test_data = data[0][:-(hours_in_future - 1)]\n",
    "    \n",
    "    for x in range (len(test_data)):\n",
    "        #Going through all the windows\n",
    "        last_window = test_data[x].reshape(1,-1)\n",
    "    \n",
    "            # Make as many predictions as hours_in_future\n",
    "        for i in range(hours_in_future):\n",
    "            \n",
    "            # Take the predicted value from the last window in training set\n",
    "            last_prediction = model.predict(last_window)[0]\n",
    "\n",
    "            #shifting the window size one step down\n",
    "            last_window[0] = np.roll(last_window[0], -1)\n",
    "\n",
    "            #replacing the old value with new prediction\n",
    "            last_window[0 , (len(last_window[0]) - 1)] = last_prediction\n",
    "\n",
    "        #append prediction\n",
    "        predictions.append(last_prediction)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "369753c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_day_predictions = steps_in_future(3, eth_test)\n",
    "five_day_predictions = steps_in_future(5, eth_test)\n",
    "seven_day_predictions = steps_in_future( 7, eth_test)\n",
    "nine_day_predictions = steps_in_future( 9, eth_test)\n",
    "eleven_day_predictions = steps_in_future( 11, eth_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "161a0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets to compare  \n",
    "\n",
    "targets_in_future_three = eth_test[1][(3 - 1):]\n",
    "targets_in_future_five = eth_test[1][(5 - 1):]\n",
    "targets_in_future_seven = eth_test[1][(7 - 1):]\n",
    "targets_in_future_nine = eth_test[1][(9 - 1):]\n",
    "targets_in_future_eleven = eth_test[1][(11 - 1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2d58c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(num_days , actual , results):\n",
    "    \n",
    "    mae = mean_absolute_error(actual , results)\n",
    "    mse = mean_squared_error(actual , results )\n",
    "    rmse = mean_squared_error(actual , results , squared = False)\n",
    "    mape = mean_absolute_percentage_error(actual , results)\n",
    "\n",
    "    print(num_days , \"MAE :\" , mae ,\"MSE :\" , mse , \"RMSE :\" , rmse , \"MAPE :\" , mape)\n",
    "\n",
    "    return mae , mse , rmse , mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1478380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three Hour Forecast MAE : 144.97334177979616 MSE : 29040.97660236416 RMSE : 170.41413263683316 MAPE : 0.037463009531038365\n",
      "Five Hour Forecast MAE : 278.1820860984048 MSE : 93385.69353563107 RMSE : 305.5907288116429 MAPE : 0.07284139264792892\n",
      "Seven Hour Forecast MAE : 453.4969083002469 MSE : 231078.09476753845 RMSE : 480.7058297623802 MAPE : 0.11999954071479813\n",
      "Nine Hour Forecast MAE : 664.0195756226311 MSE : 482699.55979735125 RMSE : 694.7658309080487 MAPE : 0.1763877282699429\n",
      "Eleven Hour Forecast MAE : 895.3884372576878 MSE : 872186.0253482417 RMSE : 933.9090027129205 MAPE : 0.23788623808046666\n"
     ]
    }
   ],
   "source": [
    "three_days_mae , three_days_mse , three_days_rmse , three_days_mape = get_eval_metrics(\"Three Hour Forecast\" , targets_in_future_three , three_day_predictions)\n",
    "five_days_mae , five_days_mse , five_days_rmse , five_days_mape = get_eval_metrics(\"Five Hour Forecast\" , targets_in_future_five , five_day_predictions)\n",
    "seven_days_mae , seven_days_mse , seven_days_rmse , seven_days_mape = get_eval_metrics(\"Seven Hour Forecast\" , targets_in_future_seven , seven_day_predictions)\n",
    "nine_days_mae , nine_days_mse , nine_days_rmse , nine_days_mape = get_eval_metrics(\"Nine Hour Forecast\" , targets_in_future_nine , nine_day_predictions)\n",
    "eleven_days_mae , eleven_days_mse , eleven_days_rmse , eleven_days_mape = get_eval_metrics(\"Eleven Hour Forecast\" , targets_in_future_eleven ,eleven_day_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d881e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
