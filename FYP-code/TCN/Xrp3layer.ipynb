{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ef1f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop , Adam\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error , mean_absolute_percentage_error\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.layers import LSTM , Dense , Dropout , GRU , Concatenate , Input , Conv1D , InputLayer , Flatten\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8a934b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xrp = pd.read_csv(\"XRP_1h_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e621e0",
   "metadata": {},
   "source": [
    "<Strong> Grabbing the closing price (univariate) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb0121cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrp_data = df_xrp.values[:, 4 ,].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc55c37",
   "metadata": {},
   "source": [
    "<Strong> Scaling the data  </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41325b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "percTrain = 70\n",
    "percVal = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffed868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "    \n",
    "onePercent = len(xrp_data) // 100\n",
    "numberTraining = onePercent * percTrain\n",
    "\n",
    "reshaped_data = xrp_data.reshape(-1,1)\n",
    "\n",
    "#Just scaling on training data otherwise it would be leakage\n",
    "scaler.fit(reshaped_data[:numberTraining])\n",
    "scaled_xrp = scaler.transform(reshaped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e217e83f",
   "metadata": {},
   "source": [
    "<Strong> Hyper-parameters </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e259f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "\n",
    "# How many hidden layers we should have \n",
    "# Learning rate\n",
    "# Kernel Size\n",
    "# Window Size\n",
    "#Filters\n",
    "\n",
    "window_length = 24\n",
    "features = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4f32e",
   "metadata": {},
   "source": [
    "<Strong> Creating Matrix in Sliding window form <Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "306195db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(elements, window_size):\n",
    "    \n",
    "    data = [] \n",
    "    targets = []\n",
    "    \n",
    "    if len(elements) <= window_size:\n",
    "        return elements\n",
    "    \n",
    "    for i in range(len(elements) - window_size ):\n",
    "        \n",
    "        data.append(elements[i:i+window_size])\n",
    "        targets.append(elements[i+window_size])\n",
    "        \n",
    "    return np.array(data) , np.array(targets)\n",
    "\n",
    "sliding_winda_xrp = sliding_window(scaled_xrp , window_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d9c6a",
   "metadata": {},
   "source": [
    "<Strong> Splitting the data into train , val , test </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6546059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data after creating the sliding window data\n",
    "def splitting_train_test(data):\n",
    "        \n",
    "    onePercent = len(data[1]) // 100\n",
    "    \n",
    "    numberTraining = onePercent * percTrain\n",
    "    numberValidation = onePercent * percVal\n",
    "    \n",
    "    trainingData = data[0][:numberTraining] , data[1][:numberTraining]\n",
    "    validationData = data[0][numberTraining : numberTraining + numberValidation] , data[1][numberTraining : numberTraining + numberValidation]\n",
    "    testData = data[0][numberTraining + numberValidation:] , data[1][numberTraining + numberValidation:] \n",
    "    \n",
    "    #Returning tuples of (sliding-window , target_values)\n",
    "    return trainingData , validationData , testData\n",
    "\n",
    "xrp_train , xrp_val , xrp_test = splitting_train_test(sliding_winda_xrp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6f787",
   "metadata": {},
   "source": [
    "<Strong> Window length 24  </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd2ecb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 24, 1)]           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 24, 64)            256       \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 24, 64)            12352     \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 24, 64)            12352     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                24592     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,569\n",
      "Trainable params: 49,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "inputs = Input(shape = (window_length , features) )\n",
    "\n",
    "x = Conv1D(filters= 64, kernel_size=3, activation='relu', dilation_rate=1 , padding = 'causal')(inputs)\n",
    "\n",
    "x = Conv1D(filters= 64, kernel_size=3, activation='relu' , padding = 'causal', dilation_rate=3)(x)\n",
    "\n",
    "x = Conv1D(filters= 64 , kernel_size=3, activation='relu' , padding = 'causal' , dilation_rate=9)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "#model.add(Dropout(0.01))\n",
    "\n",
    "x = Dense(16, activation='relu')(x)\n",
    "\n",
    "x = Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs= x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = Adam(learning_rate=0.00005)\n",
    "model.compile(optimizer=opt , loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "311cdd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0664 - val_loss: 0.5354\n",
      "Epoch 2/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.0259 - val_loss: 0.1315\n",
      "Epoch 3/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.0027 - val_loss: 0.0300\n",
      "Epoch 4/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0230\n",
      "Epoch 5/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.0918e-04 - val_loss: 0.0152\n",
      "Epoch 6/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.1022e-04 - val_loss: 0.0089\n",
      "Epoch 7/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.9633e-04 - val_loss: 0.0071\n",
      "Epoch 8/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.8864e-04 - val_loss: 0.0067\n",
      "Epoch 9/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.8297e-04 - val_loss: 0.0062\n",
      "Epoch 10/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.7386e-04 - val_loss: 0.0059\n",
      "Epoch 11/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.6512e-04 - val_loss: 0.0059\n",
      "Epoch 12/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.5714e-04 - val_loss: 0.0056\n",
      "Epoch 13/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.4901e-04 - val_loss: 0.0054\n",
      "Epoch 14/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.4187e-04 - val_loss: 0.0052\n",
      "Epoch 15/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.3419e-04 - val_loss: 0.0051\n",
      "Epoch 16/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.2707e-04 - val_loss: 0.0051\n",
      "Epoch 17/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.2035e-04 - val_loss: 0.0047\n",
      "Epoch 18/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.1310e-04 - val_loss: 0.0045\n",
      "Epoch 19/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.0347e-04 - val_loss: 0.0042\n",
      "Epoch 20/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.9472e-04 - val_loss: 0.0044\n",
      "Epoch 21/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.8721e-04 - val_loss: 0.0040\n",
      "Epoch 22/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.8091e-04 - val_loss: 0.0038\n",
      "Epoch 23/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.7297e-04 - val_loss: 0.0038\n",
      "Epoch 24/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.6735e-04 - val_loss: 0.0036\n",
      "Epoch 25/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.6118e-04 - val_loss: 0.0036\n",
      "Epoch 26/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.5544e-04 - val_loss: 0.0035\n",
      "Epoch 27/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.4962e-04 - val_loss: 0.0033\n",
      "Epoch 28/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.4377e-04 - val_loss: 0.0034\n",
      "Epoch 29/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.3892e-04 - val_loss: 0.0030\n",
      "Epoch 30/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.3282e-04 - val_loss: 0.0031\n",
      "Epoch 31/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.2838e-04 - val_loss: 0.0029\n",
      "Epoch 32/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.2312e-04 - val_loss: 0.0028\n",
      "Epoch 33/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.1715e-04 - val_loss: 0.0028\n",
      "Epoch 34/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.1351e-04 - val_loss: 0.0027\n",
      "Epoch 35/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0918e-04 - val_loss: 0.0027\n",
      "Epoch 36/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0579e-04 - val_loss: 0.0027\n",
      "Epoch 37/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0346e-04 - val_loss: 0.0026\n",
      "Epoch 38/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0162e-04 - val_loss: 0.0027\n",
      "Epoch 39/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.8154e-05 - val_loss: 0.0027\n",
      "Epoch 40/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.7046e-05 - val_loss: 0.0026\n",
      "Epoch 41/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.4575e-05 - val_loss: 0.0024\n",
      "Epoch 42/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.3682e-05 - val_loss: 0.0025\n",
      "Epoch 43/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.1529e-05 - val_loss: 0.0023\n",
      "Epoch 44/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.0011e-05 - val_loss: 0.0024\n",
      "Epoch 45/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.9276e-05 - val_loss: 0.0021\n",
      "Epoch 46/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.8385e-05 - val_loss: 0.0025\n",
      "Epoch 47/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.6353e-05 - val_loss: 0.0020\n",
      "Epoch 48/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.5270e-05 - val_loss: 0.0022\n",
      "Epoch 49/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.4284e-05 - val_loss: 0.0024\n",
      "Epoch 50/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.2391e-05 - val_loss: 0.0022\n",
      "Epoch 51/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.2048e-05 - val_loss: 0.0020\n",
      "Epoch 52/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.0934e-05 - val_loss: 0.0021\n",
      "Epoch 53/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.9491e-05 - val_loss: 0.0022\n",
      "Epoch 54/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.9061e-05 - val_loss: 0.0019\n",
      "Epoch 55/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.8476e-05 - val_loss: 0.0020\n",
      "Epoch 56/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.7020e-05 - val_loss: 0.0018\n",
      "Epoch 57/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.5566e-05 - val_loss: 0.0019\n",
      "Epoch 58/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.5273e-05 - val_loss: 0.0020\n",
      "Epoch 59/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.4165e-05 - val_loss: 0.0020\n",
      "Epoch 60/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.4233e-05 - val_loss: 0.0019\n",
      "Epoch 61/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.2187e-05 - val_loss: 0.0019\n",
      "Epoch 62/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.1402e-05 - val_loss: 0.0019\n",
      "Epoch 63/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.1160e-05 - val_loss: 0.0019\n",
      "Epoch 64/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.9978e-05 - val_loss: 0.0017\n",
      "Epoch 65/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.0961e-05 - val_loss: 0.0019\n",
      "Epoch 66/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.8667e-05 - val_loss: 0.0018\n",
      "Epoch 67/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.8226e-05 - val_loss: 0.0018\n",
      "Epoch 68/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.7139e-05 - val_loss: 0.0017\n",
      "Epoch 69/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.7687e-05 - val_loss: 0.0016\n",
      "Epoch 70/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.6232e-05 - val_loss: 0.0016\n",
      "Epoch 71/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.5356e-05 - val_loss: 0.0017\n",
      "Epoch 72/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.5026e-05 - val_loss: 0.0017\n",
      "Epoch 73/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4098e-05 - val_loss: 0.0016\n",
      "Epoch 74/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.3782e-05 - val_loss: 0.0019\n",
      "Epoch 75/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4323e-05 - val_loss: 0.0017\n",
      "Epoch 76/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.2609e-05 - val_loss: 0.0016\n",
      "Epoch 77/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.2390e-05 - val_loss: 0.0017\n",
      "Epoch 78/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.2391e-05 - val_loss: 0.0017\n",
      "Epoch 79/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.1132e-05 - val_loss: 0.0014\n",
      "Epoch 80/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.1835e-05 - val_loss: 0.0016\n",
      "Epoch 81/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.9697e-05 - val_loss: 0.0016\n",
      "Epoch 82/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.9394e-05 - val_loss: 0.0016\n",
      "Epoch 83/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.9058e-05 - val_loss: 0.0016\n",
      "Epoch 84/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.8740e-05 - val_loss: 0.0016\n",
      "Epoch 85/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.8179e-05 - val_loss: 0.0016\n",
      "Epoch 86/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.8040e-05 - val_loss: 0.0014\n",
      "Epoch 87/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.6973e-05 - val_loss: 0.0015\n",
      "Epoch 88/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.7099e-05 - val_loss: 0.0015\n",
      "Epoch 89/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.5959e-05 - val_loss: 0.0015\n",
      "Epoch 90/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.5624e-05 - val_loss: 0.0014\n",
      "Epoch 91/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.5288e-05 - val_loss: 0.0015\n",
      "Epoch 92/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.4955e-05 - val_loss: 0.0014\n",
      "Epoch 93/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.4363e-05 - val_loss: 0.0013\n",
      "Epoch 94/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.5005e-05 - val_loss: 0.0014\n",
      "Epoch 95/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.3654e-05 - val_loss: 0.0014\n",
      "Epoch 96/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.3131e-05 - val_loss: 0.0014\n",
      "Epoch 97/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.2652e-05 - val_loss: 0.0014\n",
      "Epoch 98/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.2478e-05 - val_loss: 0.0013\n",
      "Epoch 99/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.1857e-05 - val_loss: 0.0014\n",
      "Epoch 100/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.1628e-05 - val_loss: 0.0014\n",
      "Epoch 101/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.2323e-05 - val_loss: 0.0014\n",
      "Epoch 102/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.1309e-05 - val_loss: 0.0014\n",
      "Epoch 103/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.0795e-05 - val_loss: 0.0014\n",
      "Epoch 104/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.0474e-05 - val_loss: 0.0015\n",
      "Epoch 105/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.0675e-05 - val_loss: 0.0013\n",
      "Epoch 106/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.9455e-05 - val_loss: 0.0013\n",
      "Epoch 107/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.8762e-05 - val_loss: 0.0013\n",
      "Epoch 108/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.8431e-05 - val_loss: 0.0013\n",
      "Epoch 109/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.8168e-05 - val_loss: 0.0013\n",
      "Epoch 110/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.7980e-05 - val_loss: 0.0014\n",
      "Epoch 111/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.7880e-05 - val_loss: 0.0013\n",
      "Epoch 112/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.7442e-05 - val_loss: 0.0014\n",
      "Epoch 113/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.7707e-05 - val_loss: 0.0011\n",
      "Epoch 114/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.7292e-05 - val_loss: 0.0014\n",
      "Epoch 115/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.7405e-05 - val_loss: 0.0014\n",
      "Epoch 116/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.6202e-05 - val_loss: 0.0013\n",
      "Epoch 117/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.7987e-05 - val_loss: 0.0011\n",
      "Epoch 118/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.6119e-05 - val_loss: 0.0013\n",
      "Epoch 119/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.5172e-05 - val_loss: 0.0012\n",
      "Epoch 120/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.4691e-05 - val_loss: 0.0012\n",
      "Epoch 121/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.4933e-05 - val_loss: 0.0013\n",
      "Epoch 122/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.4527e-05 - val_loss: 0.0012\n",
      "Epoch 123/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.3990e-05 - val_loss: 0.0013\n",
      "Epoch 124/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.4956e-05 - val_loss: 0.0013\n",
      "Epoch 125/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.3673e-05 - val_loss: 0.0013\n",
      "Epoch 126/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.2893e-05 - val_loss: 0.0012\n",
      "Epoch 127/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.2817e-05 - val_loss: 0.0012\n",
      "Epoch 128/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.2699e-05 - val_loss: 0.0013\n",
      "Epoch 129/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.2531e-05 - val_loss: 0.0013\n",
      "Epoch 130/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.2058e-05 - val_loss: 0.0012\n",
      "Epoch 131/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.2417e-05 - val_loss: 0.0012\n",
      "Epoch 132/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.2094e-05 - val_loss: 0.0013\n",
      "Epoch 133/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.1621e-05 - val_loss: 0.0012\n",
      "Epoch 134/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.1694e-05 - val_loss: 0.0011\n",
      "Epoch 135/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.1329e-05 - val_loss: 0.0012\n",
      "Epoch 136/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.0393e-05 - val_loss: 0.0012\n",
      "Epoch 137/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.0789e-05 - val_loss: 0.0011\n",
      "Epoch 138/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.0285e-05 - val_loss: 0.0012\n",
      "Epoch 139/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.0407e-05 - val_loss: 0.0011\n",
      "Epoch 140/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.9896e-05 - val_loss: 0.0012\n",
      "Epoch 141/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.1510e-05 - val_loss: 9.8721e-04\n",
      "Epoch 142/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.1480e-05 - val_loss: 0.0011\n",
      "Epoch 143/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.9484e-05 - val_loss: 0.0011\n",
      "Epoch 144/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.9918e-05 - val_loss: 0.0011\n",
      "Epoch 145/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.8339e-05 - val_loss: 0.0011\n",
      "Epoch 146/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.9084e-05 - val_loss: 0.0012\n",
      "Epoch 147/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.8915e-05 - val_loss: 0.0011\n",
      "Epoch 148/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.8541e-05 - val_loss: 0.0011\n",
      "Epoch 149/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.7985e-05 - val_loss: 0.0012\n",
      "Epoch 150/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.7829e-05 - val_loss: 0.0012\n",
      "Epoch 151/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.7514e-05 - val_loss: 0.0010\n",
      "Epoch 152/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.7596e-05 - val_loss: 0.0010\n",
      "Epoch 153/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.7735e-05 - val_loss: 0.0011\n",
      "Epoch 154/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.7606e-05 - val_loss: 0.0010\n",
      "Epoch 155/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.7297e-05 - val_loss: 0.0011\n",
      "Epoch 156/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.6926e-05 - val_loss: 0.0011\n",
      "Epoch 157/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.7076e-05 - val_loss: 0.0011\n",
      "Epoch 158/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.6149e-05 - val_loss: 0.0010\n",
      "Epoch 159/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.6187e-05 - val_loss: 0.0013\n",
      "Epoch 160/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.6997e-05 - val_loss: 0.0011\n",
      "Epoch 161/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.5875e-05 - val_loss: 9.7763e-04\n",
      "Epoch 162/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.5454e-05 - val_loss: 0.0010\n",
      "Epoch 163/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.5673e-05 - val_loss: 0.0013\n",
      "Epoch 164/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.5590e-05 - val_loss: 0.0011\n",
      "Epoch 165/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.5736e-05 - val_loss: 0.0011\n",
      "Epoch 166/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.5704e-05 - val_loss: 0.0012\n",
      "Epoch 167/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.5721e-05 - val_loss: 0.0012\n",
      "Epoch 168/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.5416e-05 - val_loss: 9.7675e-04\n",
      "Epoch 169/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.4910e-05 - val_loss: 9.0346e-04\n",
      "Epoch 170/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.4889e-05 - val_loss: 0.0011\n",
      "Epoch 171/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.5422e-05 - val_loss: 0.0010\n",
      "Epoch 172/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.4365e-05 - val_loss: 0.0011\n",
      "Epoch 173/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.5092e-05 - val_loss: 9.1449e-04\n",
      "Epoch 174/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.4491e-05 - val_loss: 9.8155e-04\n",
      "Epoch 175/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.4645e-05 - val_loss: 8.4439e-04\n",
      "Epoch 176/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.4113e-05 - val_loss: 0.0010\n",
      "Epoch 177/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.4472e-05 - val_loss: 8.7645e-04\n",
      "Epoch 178/500\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 3.4367e-05 - val_loss: 0.0011\n",
      "Epoch 179/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 3.5436e-05 - val_loss: 0.0011\n",
      "Epoch 180/500\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 3.4383e-05 - val_loss: 0.0011\n",
      "Epoch 181/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.5154e-05 - val_loss: 0.0011\n",
      "Epoch 182/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.3925e-05 - val_loss: 0.0010\n",
      "Epoch 183/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.3045e-05 - val_loss: 9.0363e-04\n",
      "Epoch 184/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.2986e-05 - val_loss: 9.6576e-04\n",
      "Epoch 185/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.3115e-05 - val_loss: 0.0011\n",
      "Epoch 186/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.3424e-05 - val_loss: 8.7747e-04\n",
      "Epoch 187/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.2704e-05 - val_loss: 8.8709e-04\n",
      "Epoch 188/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.3101e-05 - val_loss: 9.0549e-04\n",
      "Epoch 189/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.3100e-05 - val_loss: 9.1567e-04\n",
      "Epoch 190/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.2433e-05 - val_loss: 9.6449e-04\n",
      "Epoch 191/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.2226e-05 - val_loss: 9.1752e-04\n",
      "Epoch 192/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.2438e-05 - val_loss: 0.0011\n",
      "Epoch 193/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.2635e-05 - val_loss: 8.8924e-04\n",
      "Epoch 194/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.2075e-05 - val_loss: 9.4077e-04\n",
      "Epoch 195/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.1871e-05 - val_loss: 9.4976e-04\n",
      "Epoch 196/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.2235e-05 - val_loss: 9.8115e-04\n",
      "Epoch 197/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.1654e-05 - val_loss: 8.8262e-04\n",
      "Epoch 198/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.2444e-05 - val_loss: 8.9554e-04\n",
      "Epoch 199/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.2603e-05 - val_loss: 0.0012\n",
      "Epoch 200/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.2477e-05 - val_loss: 8.9128e-04\n",
      "Epoch 201/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.1411e-05 - val_loss: 8.9138e-04\n",
      "Epoch 202/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.1684e-05 - val_loss: 0.0010\n",
      "Epoch 203/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.1708e-05 - val_loss: 9.1816e-04\n",
      "Epoch 204/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.1551e-05 - val_loss: 9.1933e-04\n",
      "Epoch 205/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 3.1413e-05 - val_loss: 8.5252e-04\n",
      "Epoch 205: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "earlyStopping = EarlyStopping(monitor = 'val_loss' , patience = 30 , mode = 'min' , verbose = 1)\n",
    "history = model.fit(xrp_train[0] , xrp_train[1] , validation_data = xrp_val  , batch_size = 512  , epochs =500 , verbose = 1 , callbacks=[earlyStopping])\n",
    "num_epochs = earlyStopping.stopped_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12689e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.ylim([0,0.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646c31fb",
   "metadata": {},
   "source": [
    "<Strong> Testing our model on the validation data once again , hyper-parameter adjustment. <Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbd9c678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01363030651831989"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_predict = model.predict(xrp_val[0])\n",
    "validation_predict = scaler.inverse_transform(validation_predict)\n",
    "\n",
    "validation_actual = scaler.inverse_transform(xrp_val[1])\n",
    "mean_absolute_error(validation_actual , validation_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adddc5f",
   "metadata": {},
   "source": [
    "<Strong> Combining the train and validation set when perfected hyper-parameters and training on fresh model. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daa29a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/204\n",
      "58/58 [==============================] - 1s 6ms/step - loss: 0.0052\n",
      "Epoch 2/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 3.9324e-04\n",
      "Epoch 3/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.7847e-04\n",
      "Epoch 4/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.0864e-04\n",
      "Epoch 5/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.8872e-04\n",
      "Epoch 6/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6663e-04\n",
      "Epoch 7/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7276e-04\n",
      "Epoch 8/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6565e-04\n",
      "Epoch 9/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.9570e-04\n",
      "Epoch 10/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5585e-04\n",
      "Epoch 11/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5319e-04\n",
      "Epoch 12/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.2084e-04\n",
      "Epoch 13/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6122e-04\n",
      "Epoch 14/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6960e-04\n",
      "Epoch 15/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7587e-04\n",
      "Epoch 16/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7220e-04\n",
      "Epoch 17/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4202e-04\n",
      "Epoch 18/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6000e-04\n",
      "Epoch 19/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7728e-04\n",
      "Epoch 20/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4051e-04\n",
      "Epoch 21/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5160e-04\n",
      "Epoch 22/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7791e-04\n",
      "Epoch 23/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5383e-04\n",
      "Epoch 24/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4424e-04\n",
      "Epoch 25/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4964e-04\n",
      "Epoch 26/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.0523e-04\n",
      "Epoch 27/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5726e-04\n",
      "Epoch 28/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4093e-04\n",
      "Epoch 29/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7946e-04\n",
      "Epoch 30/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2798e-04\n",
      "Epoch 31/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.1353e-04\n",
      "Epoch 32/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.9882e-04\n",
      "Epoch 33/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3329e-04\n",
      "Epoch 34/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2465e-04\n",
      "Epoch 35/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7750e-04\n",
      "Epoch 36/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7130e-04\n",
      "Epoch 37/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3652e-04\n",
      "Epoch 38/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5477e-04\n",
      "Epoch 39/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3697e-04\n",
      "Epoch 40/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6810e-04\n",
      "Epoch 41/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.8925e-04\n",
      "Epoch 42/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5315e-04\n",
      "Epoch 43/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4354e-04\n",
      "Epoch 44/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3123e-04\n",
      "Epoch 45/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6019e-04\n",
      "Epoch 46/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6548e-04\n",
      "Epoch 47/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5935e-04\n",
      "Epoch 48/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5579e-04\n",
      "Epoch 49/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4044e-04\n",
      "Epoch 50/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4247e-04\n",
      "Epoch 51/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.8783e-04\n",
      "Epoch 52/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.8529e-04\n",
      "Epoch 53/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4052e-04\n",
      "Epoch 54/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.1121e-04\n",
      "Epoch 55/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4622e-04\n",
      "Epoch 56/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7473e-04\n",
      "Epoch 57/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3395e-04\n",
      "Epoch 58/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3778e-04\n",
      "Epoch 59/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7188e-04\n",
      "Epoch 60/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3803e-04\n",
      "Epoch 61/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.9702e-04\n",
      "Epoch 62/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5886e-04\n",
      "Epoch 63/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3694e-04\n",
      "Epoch 64/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4681e-04\n",
      "Epoch 65/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3474e-04\n",
      "Epoch 66/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3841e-04\n",
      "Epoch 67/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7586e-04\n",
      "Epoch 68/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6533e-04\n",
      "Epoch 69/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5280e-04\n",
      "Epoch 70/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4417e-04\n",
      "Epoch 71/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4576e-04\n",
      "Epoch 72/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2917e-04\n",
      "Epoch 73/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7029e-04\n",
      "Epoch 74/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5305e-04\n",
      "Epoch 75/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4907e-04\n",
      "Epoch 76/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4981e-04\n",
      "Epoch 77/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.3369e-04\n",
      "Epoch 78/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4076e-04\n",
      "Epoch 79/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3001e-04\n",
      "Epoch 80/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2904e-04\n",
      "Epoch 81/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3707e-04\n",
      "Epoch 82/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3779e-04\n",
      "Epoch 83/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5449e-04\n",
      "Epoch 84/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3750e-04\n",
      "Epoch 85/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4170e-04\n",
      "Epoch 86/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.9849e-04\n",
      "Epoch 87/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3325e-04\n",
      "Epoch 88/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.8365e-04\n",
      "Epoch 89/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6403e-04\n",
      "Epoch 90/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3432e-04\n",
      "Epoch 91/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4083e-04\n",
      "Epoch 92/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4600e-04\n",
      "Epoch 93/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6982e-04\n",
      "Epoch 94/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5551e-04\n",
      "Epoch 95/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4942e-04\n",
      "Epoch 96/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4291e-04\n",
      "Epoch 97/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3712e-04\n",
      "Epoch 98/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6457e-04\n",
      "Epoch 99/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.0082e-04\n",
      "Epoch 100/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4987e-04\n",
      "Epoch 101/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5100e-04\n",
      "Epoch 102/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4050e-04\n",
      "Epoch 103/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5227e-04\n",
      "Epoch 104/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3025e-04\n",
      "Epoch 105/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5034e-04\n",
      "Epoch 106/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4209e-04\n",
      "Epoch 107/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3771e-04\n",
      "Epoch 108/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5209e-04\n",
      "Epoch 109/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7675e-04\n",
      "Epoch 110/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7063e-04\n",
      "Epoch 111/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2948e-04\n",
      "Epoch 112/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4044e-04\n",
      "Epoch 113/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3598e-04\n",
      "Epoch 114/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6016e-04\n",
      "Epoch 115/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2674e-04\n",
      "Epoch 116/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2651e-04\n",
      "Epoch 117/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3010e-04\n",
      "Epoch 118/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5048e-04\n",
      "Epoch 119/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5247e-04\n",
      "Epoch 120/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5621e-04\n",
      "Epoch 121/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3154e-04\n",
      "Epoch 122/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5882e-04\n",
      "Epoch 123/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2505e-04\n",
      "Epoch 124/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.8083e-04\n",
      "Epoch 125/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6132e-04\n",
      "Epoch 126/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4318e-04\n",
      "Epoch 127/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3198e-04\n",
      "Epoch 128/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6120e-04\n",
      "Epoch 129/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4891e-04\n",
      "Epoch 130/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4367e-04\n",
      "Epoch 131/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2852e-04\n",
      "Epoch 132/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6832e-04\n",
      "Epoch 133/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3810e-04\n",
      "Epoch 134/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3329e-04\n",
      "Epoch 135/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4744e-04\n",
      "Epoch 136/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4728e-04\n",
      "Epoch 137/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2926e-04\n",
      "Epoch 138/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4142e-04\n",
      "Epoch 139/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6060e-04\n",
      "Epoch 140/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4408e-04\n",
      "Epoch 141/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3122e-04\n",
      "Epoch 142/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3779e-04\n",
      "Epoch 143/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4509e-04\n",
      "Epoch 144/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5672e-04\n",
      "Epoch 145/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5267e-04\n",
      "Epoch 146/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3626e-04\n",
      "Epoch 147/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5302e-04\n",
      "Epoch 148/204\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 1.3873e-04\n",
      "Epoch 149/204\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.2293e-04\n",
      "Epoch 150/204\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 1.2468e-04\n",
      "Epoch 151/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3795e-04\n",
      "Epoch 152/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3284e-04\n",
      "Epoch 153/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3773e-04\n",
      "Epoch 154/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3085e-04\n",
      "Epoch 155/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2853e-04\n",
      "Epoch 156/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3533e-04\n",
      "Epoch 157/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5216e-04\n",
      "Epoch 158/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4676e-04\n",
      "Epoch 159/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3220e-04\n",
      "Epoch 160/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2826e-04\n",
      "Epoch 161/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3171e-04\n",
      "Epoch 162/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3608e-04\n",
      "Epoch 163/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3008e-04\n",
      "Epoch 164/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5575e-04\n",
      "Epoch 165/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6957e-04\n",
      "Epoch 166/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2423e-04\n",
      "Epoch 167/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4879e-04\n",
      "Epoch 168/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5427e-04\n",
      "Epoch 169/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3727e-04\n",
      "Epoch 170/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2695e-04\n",
      "Epoch 171/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5213e-04\n",
      "Epoch 172/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2350e-04\n",
      "Epoch 173/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5909e-04\n",
      "Epoch 174/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4382e-04\n",
      "Epoch 175/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2887e-04\n",
      "Epoch 176/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3657e-04\n",
      "Epoch 177/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4542e-04\n",
      "Epoch 178/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4448e-04\n",
      "Epoch 179/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3835e-04\n",
      "Epoch 180/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4334e-04\n",
      "Epoch 181/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4630e-04\n",
      "Epoch 182/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2905e-04\n",
      "Epoch 183/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4991e-04\n",
      "Epoch 184/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3828e-04\n",
      "Epoch 185/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5598e-04\n",
      "Epoch 186/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4862e-04\n",
      "Epoch 187/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2781e-04\n",
      "Epoch 188/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2161e-04\n",
      "Epoch 189/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.7171e-04\n",
      "Epoch 190/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3192e-04\n",
      "Epoch 191/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4657e-04\n",
      "Epoch 192/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2629e-04\n",
      "Epoch 193/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5297e-04\n",
      "Epoch 194/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3574e-04\n",
      "Epoch 195/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2082e-04\n",
      "Epoch 196/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2856e-04\n",
      "Epoch 197/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3144e-04\n",
      "Epoch 198/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4338e-04\n",
      "Epoch 199/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5571e-04\n",
      "Epoch 200/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2520e-04\n",
      "Epoch 201/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3196e-04\n",
      "Epoch 202/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2994e-04\n",
      "Epoch 203/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2386e-04\n",
      "Epoch 204/204\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3252e-04\n"
     ]
    }
   ],
   "source": [
    "train_and_val = np.concatenate([xrp_train[0] , xrp_val[0]] )\n",
    "train_and_val_targets = np.concatenate([xrp_train[1] , xrp_val[1] ])\n",
    "\n",
    "freshModel = tf.keras.Model(inputs=inputs, outputs= x)\n",
    "\n",
    "freshModel.compile(optimizer='adam' , loss = 'mse')\n",
    "final = freshModel.fit(train_and_val , train_and_val_targets , batch_size = 512  , epochs = num_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb263691",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = freshModel.predict(xrp_test[0])\n",
    "test_actual = xrp_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cce0df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009305881486130863\n",
      "0.009449687685936082\n",
      "0.012801307746341414\n",
      "0.00016387348001654068\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(test_actual , test_predict))\n",
    "print(mean_absolute_percentage_error(test_actual , test_predict))\n",
    "print(mean_squared_error(test_actual , test_predict , squared = False))\n",
    "print(mean_squared_error(test_actual , test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc45e0e",
   "metadata": {},
   "source": [
    "<Strong> For Predicting more than 1 day in the future - Test Set. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d172d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steps_in_future(hours_in_future , data):\n",
    "    \n",
    "    #All the hours_in_future time predictions\n",
    "    predictions = []\n",
    "    \n",
    "    # Have to cut off the (hours_in_future - 1) off the test set to avoid out of bounds error\n",
    "    test_data = data[0][:-(hours_in_future - 1)]\n",
    "    \n",
    "    for x in range (len(test_data)):\n",
    "        #Going through all the windows\n",
    "        last_window = test_data[x].reshape(1,-1)\n",
    "    \n",
    "            # Make as many predictions as hours_in_future\n",
    "        for i in range(hours_in_future):\n",
    "            \n",
    "            # Take the predicted value from the last window in training set\n",
    "            last_prediction = model.predict(last_window)[0]\n",
    "\n",
    "            #shifting the window size one step down\n",
    "            last_window[0] = np.roll(last_window[0], -1)\n",
    "\n",
    "            #replacing the old value with new prediction\n",
    "            last_window[0 , (len(last_window[0]) - 1)] = last_prediction\n",
    "\n",
    "        #append prediction\n",
    "        predictions.append(last_prediction)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e324789",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_day_predictions = steps_in_future(3, xrp_test)\n",
    "five_day_predictions = steps_in_future(5, xrp_test)\n",
    "seven_day_predictions = steps_in_future( 7, xrp_test)\n",
    "nine_day_predictions = steps_in_future( 9, xrp_test)\n",
    "eleven_day_predictions = steps_in_future( 11, xrp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bdb2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets to compare  \n",
    "targets_in_future_three = xrp_test[1][(3 - 1):]\n",
    "targets_in_future_five = xrp_test[1][(5 - 1):]\n",
    "targets_in_future_seven = xrp_test[1][(7 - 1):]\n",
    "targets_in_future_nine = xrp_test[1][(9 - 1):]\n",
    "targets_in_future_eleven = xrp_test[1][(11 - 1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e1cfd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(num_days , actual , results):\n",
    "    \n",
    "    mae = mean_absolute_error(actual , results)\n",
    "    mse = mean_squared_error(actual , results )\n",
    "    rmse = mean_squared_error(actual , results , squared = False)\n",
    "    mape = mean_absolute_percentage_error(actual , results)\n",
    "\n",
    "    print(num_days , \"MAE :\" , mae ,\"MSE :\" , mse , \"RMSE :\" , rmse , \"MAPE :\" , mape)\n",
    "\n",
    "    return mae , mse , rmse , mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d2722b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three Hour Forecast MAE : 0.02326485867703767 MSE : 0.0008504825631658062 RMSE : 0.029163034189977663 MAPE : 0.023029172734163352\n",
      "Five Hour Forecast MAE : 0.05406635835525207 MSE : 0.0038914259310996622 RMSE : 0.06238129472125167 MAPE : 0.0526677790018306\n",
      "Seven Hour Forecast MAE : 0.10115953810775952 MSE : 0.012746716039664792 RMSE : 0.11290135534910462 MAPE : 0.0977385096686006\n",
      "Nine Hour Forecast MAE : 0.1613581831697701 MSE : 0.03154999617865422 RMSE : 0.17762318592642748 MAPE : 0.15537490501756362\n",
      "Eleven Hour Forecast MAE : 0.23585612209835444 MSE : 0.0661779612319603 RMSE : 0.2572507749880655 MAPE : 0.2271476286873232\n"
     ]
    }
   ],
   "source": [
    "three_days_mae , three_days_mse , three_days_rmse , three_days_mape = get_eval_metrics(\"Three Hour Forecast\" , targets_in_future_three , three_day_predictions)\n",
    "five_days_mae , five_days_mse , five_days_rmse , five_days_mape = get_eval_metrics(\"Five Hour Forecast\" , targets_in_future_five , five_day_predictions)\n",
    "seven_days_mae , seven_days_mse , seven_days_rmse , seven_days_mape = get_eval_metrics(\"Seven Hour Forecast\" , targets_in_future_seven ,seven_day_predictions)\n",
    "nine_days_mae , nine_days_mse , nine_days_rmse , nine_days_mape = get_eval_metrics(\"Nine Hour Forecast\" , targets_in_future_nine , nine_day_predictions)\n",
    "eleven_days_mae , eleven_days_mse , eleven_days_rmse , eleven_days_mape = get_eval_metrics(\"Eleven Hour Forecast\" , targets_in_future_eleven , eleven_day_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
