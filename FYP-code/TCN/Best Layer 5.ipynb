{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037c8e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from IPython.display import display, Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error , mean_absolute_percentage_error\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.layers import LSTM , Dense , Dropout , GRU , Concatenate , Flatten , Input , Conv1D , InputLayer , MaxPooling1D\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6fcad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc = pd.read_csv(\"BTC_1h_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc4804e",
   "metadata": {},
   "source": [
    "<Strong> Grabbing the closing price (univariate) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5548cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_data = df_btc.values[:, 4 ,].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83358d",
   "metadata": {},
   "source": [
    "<Strong> Scaling the data  </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1645d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "percTrain = 70\n",
    "percVal = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1885c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "    \n",
    "onePercent = len(btc_data) // 100\n",
    "numberTraining = onePercent * percTrain\n",
    "\n",
    "reshaped_data = btc_data.reshape(-1,1)\n",
    "\n",
    "#Just scaling on training data otherwise it would be leakage\n",
    "scaler.fit(reshaped_data[:numberTraining])\n",
    "scaled_btc = scaler.transform(reshaped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64beec85",
   "metadata": {},
   "source": [
    "<Strong> Hyper-parameters </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9022583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters that are dependant on the number of layers \n",
    "\n",
    "# Dilation_rate\n",
    "# window_length \n",
    "# kernel_size\n",
    "\n",
    "# The rest of the hyper-parameter\n",
    "\n",
    "# learning_rate\n",
    "# Dense layer size\n",
    "# filters \n",
    "# batch_size\n",
    "\n",
    "window_length = 72\n",
    "dilation_rate = 2\n",
    "kernel_size = 2\n",
    "features = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9fda9c",
   "metadata": {},
   "source": [
    "<Strong> Creating Matrix in Sliding window form <Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0300c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(elements, window_size):\n",
    "    \n",
    "    data = [] \n",
    "    targets = []\n",
    "    \n",
    "    if len(elements) <= window_size:\n",
    "        return elements\n",
    "    \n",
    "    for i in range(len(elements) - window_size ):\n",
    "        \n",
    "        data.append(elements[i:i+window_size])\n",
    "        targets.append(elements[i+window_size])\n",
    "        \n",
    "    return np.array(data) , np.array(targets)\n",
    "\n",
    "sliding_winda_btc = sliding_window(scaled_btc , window_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbb9b6",
   "metadata": {},
   "source": [
    "<Strong> Splitting the data into train , val , test </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe5079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data after creating the sliding window data\n",
    "def splitting_train_test(data):\n",
    "        \n",
    "    onePercent = len(data[1]) // 100\n",
    "    \n",
    "    numberTraining = onePercent * percTrain\n",
    "    numberValidation = onePercent * percVal\n",
    "    \n",
    "    trainingData = data[0][:numberTraining] , data[1][:numberTraining]\n",
    "    validationData = data[0][numberTraining : numberTraining + numberValidation] , data[1][numberTraining : numberTraining + numberValidation]\n",
    "    testData = data[0][numberTraining + numberValidation:] , data[1][numberTraining + numberValidation:] \n",
    "    \n",
    "    #Returning tuples of (sliding-window , target_values)\n",
    "    return trainingData , validationData , testData\n",
    "\n",
    "btc_train , btc_val , btc_test = splitting_train_test(sliding_winda_btc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=2, activation='relu', input_shape=(window_length, 1), dilation_rate=1 , padding = 'causal'))\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=2, activation='relu' , padding = 'causal', dilation_rate=2))\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=2, activation='relu' , padding = 'causal' , dilation_rate=4))\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=2, activation='relu' , padding = 'causal', dilation_rate= 8))\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=2, activation='relu' , padding = 'causal', dilation_rate= 16))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(32))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "opt = Adam(0.004)\n",
    "model.compile(optimizer=opt , loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539181db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "earlyStopping = EarlyStopping(monitor = 'val_loss' , patience = 30 , mode = 'min' , verbose = 1)\n",
    "history = model.fit(btc_train[0] , btc_train[1] , validation_data = btc_val  , batch_size = 512  , epochs =300 , verbose = 1 , callbacks=[earlyStopping])\n",
    "num_epochs = earlyStopping.stopped_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df43cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "#plt.ylim([0,0.01])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
