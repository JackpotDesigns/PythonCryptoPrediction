{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "434fdab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop , Adam\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error , mean_absolute_percentage_error\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.layers import LSTM , Dense , Dropout , GRU , Concatenate , Input , Conv1D , InputLayer , Flatten\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3969872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc = pd.read_csv(\"BTC_1h_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b972036",
   "metadata": {},
   "source": [
    "<Strong> Grabbing the closing price (univariate) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20b18a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_data = df_btc.values[:, 4 ,].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518c920",
   "metadata": {},
   "source": [
    "<Strong> Scaling the data  </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a041ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "percTrain = 70\n",
    "percVal = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "544cffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "    \n",
    "onePercent = len(btc_data) // 100\n",
    "numberTraining = onePercent * percTrain\n",
    "\n",
    "reshaped_data = btc_data.reshape(-1,1)\n",
    "\n",
    "#Just scaling on training data otherwise it would be leakage\n",
    "scaler.fit(reshaped_data[:numberTraining])\n",
    "scaled_btc = scaler.transform(reshaped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704aa482",
   "metadata": {},
   "source": [
    "<Strong> Hyper-parameters </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d40b1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "\n",
    "# How many hidden layers we should have \n",
    "# Learning rate\n",
    "# Kernel Size\n",
    "# Window Size\n",
    "#Filters\n",
    "\n",
    "window_length = 120\n",
    "features = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5babd96c",
   "metadata": {},
   "source": [
    "<Strong> Creating Matrix in Sliding window form <Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0467d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(elements, window_size):\n",
    "    \n",
    "    data = [] \n",
    "    targets = []\n",
    "    \n",
    "    if len(elements) <= window_size:\n",
    "        return elements\n",
    "    \n",
    "    for i in range(len(elements) - window_size ):\n",
    "        \n",
    "        data.append(elements[i:i+window_size])\n",
    "        targets.append(elements[i+window_size])\n",
    "        \n",
    "    return np.array(data) , np.array(targets)\n",
    "\n",
    "sliding_winda_btc = sliding_window(scaled_btc , window_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3951e0",
   "metadata": {},
   "source": [
    "<Strong> Splitting the data into train , val , test </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7ad5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data after creating the sliding window data\n",
    "def splitting_train_test(data):\n",
    "        \n",
    "    onePercent = len(data[1]) // 100\n",
    "    \n",
    "    numberTraining = onePercent * percTrain\n",
    "    numberValidation = onePercent * percVal\n",
    "    \n",
    "    trainingData = data[0][:numberTraining] , data[1][:numberTraining]\n",
    "    validationData = data[0][numberTraining : numberTraining + numberValidation] , data[1][numberTraining : numberTraining + numberValidation]\n",
    "    testData = data[0][numberTraining + numberValidation:] , data[1][numberTraining + numberValidation:] \n",
    "    \n",
    "    #Returning tuples of (sliding-window , target_values)\n",
    "    return trainingData , validationData , testData\n",
    "\n",
    "btc_train , btc_val , btc_test = splitting_train_test(sliding_winda_btc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c326b024",
   "metadata": {},
   "source": [
    "<Strong> The number of layers while changing dilation_base , kernel_size or window_size. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f778f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayers(dilation_rate , window_size , kernel_size):\n",
    "    \n",
    "    top = (dilation_rate - 1) * (window_size - 1)\n",
    "    bottom = (kernel_size - 1) \n",
    "    \n",
    "    division = (top / bottom) + 1 \n",
    "    log = math.ceil(math.log(division , dilation_rate))\n",
    "    \n",
    "    \n",
    "    # This inequality must hold true for full coverage\n",
    "    \n",
    "    first = 1 + (kernel_size - 1)\n",
    "    second = (dilation_rate ** log ) - 1\n",
    "    third = dilation_rate - 1\n",
    "    \n",
    "    inequality = (second / third) * first\n",
    "    \n",
    "    if ( (kernel_size < dilation_rate) or (inequality < window_size) ):\n",
    "        print(\"not going to have full coverage\")\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        print(\"layers =\" , log , \"dilation rate =\" , dilation_rate , \"kernel size =\" , kernel_size , )\n",
    "        return log , dilation_rate , kernel_size\n",
    "\n",
    "getLayers( 5 , 24 , 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d21c009",
   "metadata": {},
   "source": [
    "<Strong> First 3-Layer Model with <i> dilation_rate = 3 </i> and <i> kernel_size = 3 </i> </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25bf9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelThreeLayers(hp):\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate' , values = [0.002 , 0.004 , 0.006])\n",
    "    hp_dense_layer = hp.Choice('dense_layer' , values = [16 , 32 , 64 ])\n",
    "    hp_filters = hp.Choice ('filters' , values = [8 , 16 , 32])\n",
    "    hp_dropout = hp.Choice('dropout' , values = [0.01 , 0.05 , 0.1])\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters= hp_filters, kernel_size=3, activation='relu', input_shape=(window_length, 1), dilation_rate=1 , padding = 'causal'))\n",
    "\n",
    "    model.add(Conv1D(filters= hp_filters, kernel_size=3, activation='relu' , padding = 'causal', dilation_rate=3))\n",
    "\n",
    "    model.add(Conv1D(filters= hp_filters , kernel_size=3, activation='relu' , padding = 'causal' , dilation_rate=9))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(hp_dropout))\n",
    "    \n",
    "    model.add(Dense(hp_dense_layer, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    opt = Adam(learning_rate=hp_learning_rate)\n",
    "    model.compile(optimizer=opt , loss = 'mse')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b845346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tcn/tcn_3_layers/oracle.json\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 72, 8)             32        \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 72, 8)             200       \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 72, 8)             200       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                9232      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,681\n",
      "Trainable params: 9,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Reloading Tuner from tcn/tcn_3_layers/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 11:11:27.102642: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-03-30 11:11:27.102698: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (deeplearning-8-vm): /proc/driver/nvidia/version does not exist\n",
      "2022-03-30 11:11:27.103296: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch (\n",
    "    createModelThreeLayers,\n",
    "    objective = \"val_loss\",\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    directory = 'tcn',\n",
    "    project_name='tcn_3_layers'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f99a9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 Complete [00h 00m 59s]\n",
      "val_loss: 0.007848179899156094\n",
      "\n",
      "Best val_loss So Far: 0.0005827820277772844\n",
      "Total elapsed time: 00h 35m 19s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(btc_train[0] , btc_train[1] , epochs=300 , validation_data=btc_val , batch_size = 512 , callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=30)] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d43a8e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in tcn/tcn_layers_learningrate\n",
      "Showing 10 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.002\n",
      "dense_layer: 32\n",
      "filters: 16\n",
      "Score: 0.0005147327901795506\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.004\n",
      "dense_layer: 64\n",
      "filters: 8\n",
      "Score: 0.0005232560215517879\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.004\n",
      "dense_layer: 32\n",
      "filters: 16\n",
      "Score: 0.0005244296044111252\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.002\n",
      "dense_layer: 32\n",
      "filters: 8\n",
      "Score: 0.0005254821735434234\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.004\n",
      "dense_layer: 128\n",
      "filters: 8\n",
      "Score: 0.0005265726940706372\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.002\n",
      "dense_layer: 64\n",
      "filters: 8\n",
      "Score: 0.0005280636833049357\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.002\n",
      "dense_layer: 128\n",
      "filters: 8\n",
      "Score: 0.0005360119976103306\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.004\n",
      "dense_layer: 128\n",
      "filters: 32\n",
      "Score: 0.0005582605954259634\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.008\n",
      "dense_layer: 128\n",
      "filters: 8\n",
      "Score: 0.0005746590322814882\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "dense_layer: 128\n",
      "filters: 32\n",
      "Score: 0.0005765998503193259\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d91dec",
   "metadata": {},
   "source": [
    "<Strong> Creating model and graphing results from tuner search. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d2e6cfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "54/54 [==============================] - 2s 33ms/step - loss: 0.0070 - val_loss: 0.0226\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 9.9229e-04 - val_loss: 0.0265\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 6.7592e-04 - val_loss: 0.0293\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 3.7821e-04 - val_loss: 0.0198\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 2.0846e-04 - val_loss: 0.0163\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 1.3120e-04 - val_loss: 0.0173\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 1.0422e-04 - val_loss: 0.0201\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 9.9132e-05 - val_loss: 0.0119\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 9.7422e-05 - val_loss: 0.0146\n",
      "Epoch 10/300\n",
      "54/54 [==============================] - 2s 45ms/step - loss: 8.6429e-05 - val_loss: 0.0179\n",
      "Epoch 11/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 8.2352e-05 - val_loss: 0.0195\n",
      "Epoch 12/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 7.7728e-05 - val_loss: 0.0131\n",
      "Epoch 13/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 7.4929e-05 - val_loss: 0.0166\n",
      "Epoch 14/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 7.5800e-05 - val_loss: 0.0150\n",
      "Epoch 15/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 7.2370e-05 - val_loss: 0.0130\n",
      "Epoch 16/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 6.8960e-05 - val_loss: 0.0171\n",
      "Epoch 17/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 7.8095e-05 - val_loss: 0.0125\n",
      "Epoch 18/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 8.0588e-05 - val_loss: 0.0100\n",
      "Epoch 19/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 7.2169e-05 - val_loss: 0.0136\n",
      "Epoch 20/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 7.3755e-05 - val_loss: 0.0133\n",
      "Epoch 21/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 6.8005e-05 - val_loss: 0.0114\n",
      "Epoch 22/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 6.7963e-05 - val_loss: 0.0096\n",
      "Epoch 23/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 7.0664e-05 - val_loss: 0.0083\n",
      "Epoch 24/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 8.6709e-05 - val_loss: 0.0124\n",
      "Epoch 25/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.7497e-05 - val_loss: 0.0113\n",
      "Epoch 26/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 6.1409e-05 - val_loss: 0.0117\n",
      "Epoch 27/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 6.4140e-05 - val_loss: 0.0211\n",
      "Epoch 28/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 6.6602e-05 - val_loss: 0.0096\n",
      "Epoch 29/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 7.6142e-05 - val_loss: 0.0117\n",
      "Epoch 30/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.5692e-05 - val_loss: 0.0107\n",
      "Epoch 31/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.8839e-05 - val_loss: 0.0150\n",
      "Epoch 32/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.8156e-05 - val_loss: 0.0130\n",
      "Epoch 33/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 6.0242e-05 - val_loss: 0.0087\n",
      "Epoch 34/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 6.2556e-05 - val_loss: 0.0079\n",
      "Epoch 35/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 6.2107e-05 - val_loss: 0.0120\n",
      "Epoch 36/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.7342e-05 - val_loss: 0.0069\n",
      "Epoch 37/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 7.9698e-05 - val_loss: 0.0154\n",
      "Epoch 38/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.8467e-05 - val_loss: 0.0091\n",
      "Epoch 39/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.0644e-05 - val_loss: 0.0079\n",
      "Epoch 40/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 7.4742e-05 - val_loss: 0.0106\n",
      "Epoch 41/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 6.3423e-05 - val_loss: 0.0075\n",
      "Epoch 42/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.3687e-05 - val_loss: 0.0107\n",
      "Epoch 43/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 7.7055e-05 - val_loss: 0.0070\n",
      "Epoch 44/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.5422e-05 - val_loss: 0.0065\n",
      "Epoch 45/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 6.9013e-05 - val_loss: 0.0094\n",
      "Epoch 46/300\n",
      "54/54 [==============================] - 2s 46ms/step - loss: 5.9650e-05 - val_loss: 0.0135\n",
      "Epoch 47/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.9720e-05 - val_loss: 0.0099\n",
      "Epoch 48/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 6.1942e-05 - val_loss: 0.0076\n",
      "Epoch 49/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.0291e-05 - val_loss: 0.0083\n",
      "Epoch 50/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.5433e-05 - val_loss: 0.0067\n",
      "Epoch 51/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.0852e-05 - val_loss: 0.0072\n",
      "Epoch 52/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.7191e-05 - val_loss: 0.0093\n",
      "Epoch 53/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.3544e-05 - val_loss: 0.0078\n",
      "Epoch 54/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 6.6283e-05 - val_loss: 0.0071\n",
      "Epoch 55/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.7176e-05 - val_loss: 0.0082\n",
      "Epoch 56/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.3340e-05 - val_loss: 0.0065\n",
      "Epoch 57/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.6573e-05 - val_loss: 0.0093\n",
      "Epoch 58/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.2323e-05 - val_loss: 0.0069\n",
      "Epoch 59/300\n",
      "54/54 [==============================] - 2s 32ms/step - loss: 6.0388e-05 - val_loss: 0.0069\n",
      "Epoch 60/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 4.6395e-05 - val_loss: 0.0102\n",
      "Epoch 61/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.8622e-05 - val_loss: 0.0066\n",
      "Epoch 62/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.7545e-05 - val_loss: 0.0078\n",
      "Epoch 63/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.2108e-05 - val_loss: 0.0080\n",
      "Epoch 64/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 4.9912e-05 - val_loss: 0.0082\n",
      "Epoch 65/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 6.5594e-05 - val_loss: 0.0094\n",
      "Epoch 66/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.6297e-05 - val_loss: 0.0079\n",
      "Epoch 67/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.5743e-05 - val_loss: 0.0089\n",
      "Epoch 68/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 4.7389e-05 - val_loss: 0.0067\n",
      "Epoch 69/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.0867e-05 - val_loss: 0.0051\n",
      "Epoch 70/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.5430e-05 - val_loss: 0.0099\n",
      "Epoch 71/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 6.2070e-05 - val_loss: 0.0064\n",
      "Epoch 72/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.1229e-05 - val_loss: 0.0070\n",
      "Epoch 73/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.3994e-05 - val_loss: 0.0098\n",
      "Epoch 74/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.3040e-05 - val_loss: 0.0060\n",
      "Epoch 75/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.8899e-05 - val_loss: 0.0104\n",
      "Epoch 76/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 4.4815e-05 - val_loss: 0.0083\n",
      "Epoch 77/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 4.4884e-05 - val_loss: 0.0130\n",
      "Epoch 78/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.4352e-05 - val_loss: 0.0098\n",
      "Epoch 79/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 4.3136e-05 - val_loss: 0.0060\n",
      "Epoch 80/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.2166e-05 - val_loss: 0.0095\n",
      "Epoch 81/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.0036e-05 - val_loss: 0.0069\n",
      "Epoch 82/300\n",
      "54/54 [==============================] - 2s 44ms/step - loss: 4.9620e-05 - val_loss: 0.0068\n",
      "Epoch 83/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.6860e-05 - val_loss: 0.0070\n",
      "Epoch 84/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.4769e-05 - val_loss: 0.0063\n",
      "Epoch 85/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.0887e-05 - val_loss: 0.0074\n",
      "Epoch 86/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.6080e-05 - val_loss: 0.0143\n",
      "Epoch 87/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 5.0612e-05 - val_loss: 0.0084\n",
      "Epoch 88/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.6808e-05 - val_loss: 0.0131\n",
      "Epoch 89/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.2191e-05 - val_loss: 0.0124\n",
      "Epoch 90/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.4774e-05 - val_loss: 0.0094\n",
      "Epoch 91/300\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 4.3239e-05 - val_loss: 0.0073\n",
      "Epoch 92/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.8261e-05 - val_loss: 0.0076\n",
      "Epoch 93/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.1939e-05 - val_loss: 0.0079\n",
      "Epoch 94/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.2935e-05 - val_loss: 0.0075\n",
      "Epoch 95/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.3149e-05 - val_loss: 0.0074\n",
      "Epoch 96/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.5846e-05 - val_loss: 0.0086\n",
      "Epoch 97/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.1568e-05 - val_loss: 0.0067\n",
      "Epoch 98/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 5.1678e-05 - val_loss: 0.0109\n",
      "Epoch 99/300\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 4.4469e-05 - val_loss: 0.0120\n",
      "Epoch 99: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "earlyStopping = EarlyStopping(monitor = 'val_loss' , patience = 30 , mode = 'min' , verbose = 1)\n",
    "history = model.fit(btc_train[0] , btc_train[1] , validation_data = btc_val  , batch_size = 512  , epochs =300 , verbose = 1 , callbacks=[earlyStopping])\n",
    "num_epochs = earlyStopping.stopped_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01123e",
   "metadata": {},
   "source": [
    "<Strong> Second 3-Layer Model with <i> dilation_rate = 3 </i> and <i> kernel_size = 5 </i> </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a832ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelThreeLayerSecond(hp):\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate' , values = [0.002 , 0.004 , 0.006])\n",
    "    hp_dense_layer = hp.Choice('dense_layer' , values = [16 , 32 , 64])\n",
    "    hp_filters = hp.Choice ('filters' , values = [8 , 16 , 32])\n",
    "    hp_dropout = hp.Choice ('dropout' , values = [0.01 , 0.05 , 0.1])\n",
    "    \n",
    "\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=hp_filters, kernel_size=5, activation='relu', input_shape=(window_length, 1), dilation_rate=1 , padding = 'causal'))\n",
    "\n",
    "    model.add(Conv1D(filters=hp_filters, kernel_size=5, activation='relu' , padding = 'causal', dilation_rate=3))\n",
    "\n",
    "    model.add(Conv1D(filters=hp_filters, kernel_size=5, activation='relu' , padding = 'causal' , dilation_rate=9))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(hp_dropout))\n",
    "    \n",
    "    model.add(Dense(hp_dense_layer, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    opt = Adam(learning_rate=hp_learning_rate)\n",
    "    model.compile(optimizer=opt , loss = 'mse')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12555161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 120, 8)            48        \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 120, 8)            328       \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 120, 8)            328       \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 960)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 960)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                15376     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,097\n",
      "Trainable params: 16,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch (\n",
    "    createModelThreeLayerSecond,\n",
    "    objective = \"val_loss\",\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    directory = 'tcn',\n",
    "    project_name='tcn_3_layers_second_tuner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a755213d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Complete [00h 02m 41s]\n",
      "val_loss: 0.005591655615717173\n",
      "\n",
      "Best val_loss So Far: 0.0006310325115919113\n",
      "Total elapsed time: 00h 33m 23s\n",
      "\n",
      "Search: Running Trial #10\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "learning_rate     |0.002             |0.004             \n",
      "dense_layer       |32                |16                \n",
      "filters           |32                |16                \n",
      "dropout           |0.05              |0.01              \n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 120, 32)           192       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 120, 32)           5152      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 120, 32)           5152      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3840)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3840)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                122912    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,441\n",
      "Trainable params: 133,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "54/54 [==============================] - 5s 75ms/step - loss: 0.0053 - val_loss: 0.0214\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0010 - val_loss: 0.0206\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 5s 91ms/step - loss: 7.6865e-04 - val_loss: 0.0123\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 6.3857e-04 - val_loss: 0.0091\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 4.6252e-04 - val_loss: 0.0092\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 3.8153e-04 - val_loss: 0.0079\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 2.5520e-04 - val_loss: 0.0052\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 2.3329e-04 - val_loss: 0.0136\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 2.3198e-04 - val_loss: 0.0023\n",
      "Epoch 10/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 1.8086e-04 - val_loss: 0.0033\n",
      "Epoch 11/300\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 1.6356e-04 - val_loss: 0.0022\n",
      "Epoch 12/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 1.7000e-04 - val_loss: 0.0065\n",
      "Epoch 13/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 1.5562e-04 - val_loss: 0.0082\n",
      "Epoch 14/300\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 1.3992e-04 - val_loss: 0.0019\n",
      "Epoch 15/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 1.2793e-04 - val_loss: 0.0057\n",
      "Epoch 16/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 1.2839e-04 - val_loss: 0.0019\n",
      "Epoch 17/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 1.1130e-04 - val_loss: 0.0075\n",
      "Epoch 18/300\n",
      "54/54 [==============================] - 5s 90ms/step - loss: 1.2226e-04 - val_loss: 0.0188\n",
      "Epoch 19/300\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 1.2318e-04 - val_loss: 0.0013\n",
      "Epoch 20/300\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 1.0346e-04 - val_loss: 0.0038\n",
      "Epoch 21/300\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 1.2403e-04 - val_loss: 0.0221\n",
      "Epoch 22/300\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 1.3099e-04 - val_loss: 0.0063\n",
      "Epoch 23/300\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 8.8470e-05 - val_loss: 0.0049\n",
      "Epoch 24/300\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 1.0147e-04 - val_loss: 0.0096\n",
      "Epoch 25/300\n",
      "48/54 [=========================>....] - ETA: 0s - loss: 1.0227e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10275/2605350337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbtc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbtc_val\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# objective left unspecified,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(btc_train[0] , btc_train[1] , epochs=300 , validation_data=btc_val , batch_size = 512 , callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=30)] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa4ca04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in tcn/tcn_3_layers_second\n",
      "Showing 10 best trials\n",
      "Objective(name='val_loss', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.002\n",
      "dense_layer: 16\n",
      "filters: 32\n",
      "Score: 0.0005128354532644153\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.002\n",
      "dense_layer: 64\n",
      "filters: 16\n",
      "Score: 0.0005251059192232788\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.008\n",
      "dense_layer: 32\n",
      "filters: 32\n",
      "Score: 0.000525432697031647\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.004\n",
      "dense_layer: 32\n",
      "filters: 16\n",
      "Score: 0.0005339287454262376\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "dense_layer: 32\n",
      "filters: 16\n",
      "Score: 0.0005345743848010898\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.004\n",
      "dense_layer: 64\n",
      "filters: 16\n",
      "Score: 0.000538633787073195\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.004\n",
      "dense_layer: 16\n",
      "filters: 16\n",
      "Score: 0.0005447531584650278\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "dense_layer: 128\n",
      "filters: 16\n",
      "Score: 0.0005499249673448503\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.008\n",
      "dense_layer: 128\n",
      "filters: 32\n",
      "Score: 0.0005541782011277974\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "dense_layer: 16\n",
      "filters: 32\n",
      "Score: 0.0005558509728871286\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "29f15dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "54/54 [==============================] - 2s 26ms/step - loss: 0.0131 - val_loss: 0.0312\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0025 - val_loss: 0.0195\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0023 - val_loss: 0.0143\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0021 - val_loss: 0.0239\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0019 - val_loss: 0.0143\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0475\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0016 - val_loss: 0.0300\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0015 - val_loss: 0.0230\n",
      "Epoch 10/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0013 - val_loss: 0.0072\n",
      "Epoch 11/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0013 - val_loss: 0.0343\n",
      "Epoch 12/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0093\n",
      "Epoch 13/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0012 - val_loss: 0.0402\n",
      "Epoch 14/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.0012 - val_loss: 0.0479\n",
      "Epoch 15/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 16/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.0011 - val_loss: 0.0187\n",
      "Epoch 17/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0167\n",
      "Epoch 18/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0111\n",
      "Epoch 19/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0152\n",
      "Epoch 20/300\n",
      "54/54 [==============================] - 2s 39ms/step - loss: 0.0011 - val_loss: 0.0178\n",
      "Epoch 21/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.0011 - val_loss: 0.0329\n",
      "Epoch 22/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0217\n",
      "Epoch 23/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0346\n",
      "Epoch 24/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0371\n",
      "Epoch 25/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0099\n",
      "Epoch 26/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0082\n",
      "Epoch 27/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0444\n",
      "Epoch 28/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0225\n",
      "Epoch 29/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0250\n",
      "Epoch 30/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0129\n",
      "Epoch 31/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0108\n",
      "Epoch 32/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0096\n",
      "Epoch 33/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0114\n",
      "Epoch 34/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0489\n",
      "Epoch 35/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0135\n",
      "Epoch 36/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0638\n",
      "Epoch 37/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.0011 - val_loss: 0.0164\n",
      "Epoch 38/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0294\n",
      "Epoch 39/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0042\n",
      "Epoch 40/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0032\n",
      "Epoch 41/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0084\n",
      "Epoch 42/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 43/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0157\n",
      "Epoch 44/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 45/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0162\n",
      "Epoch 46/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.0010 - val_loss: 0.0113\n",
      "Epoch 47/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 48/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 49/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 50/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0245\n",
      "Epoch 51/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0011 - val_loss: 0.0110\n",
      "Epoch 52/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0140\n",
      "Epoch 53/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0118\n",
      "Epoch 54/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0082\n",
      "Epoch 55/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.0010 - val_loss: 0.0100\n",
      "Epoch 56/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 9.0889e-04 - val_loss: 0.0038\n",
      "Epoch 57/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.6501e-04 - val_loss: 0.0210\n",
      "Epoch 58/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.3158e-04 - val_loss: 0.0021\n",
      "Epoch 59/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.5015e-04 - val_loss: 0.0175\n",
      "Epoch 60/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.4746e-04 - val_loss: 0.0083\n",
      "Epoch 61/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.9103e-04 - val_loss: 0.0113\n",
      "Epoch 62/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.2637e-04 - val_loss: 0.0390\n",
      "Epoch 63/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.5003e-04 - val_loss: 0.0025\n",
      "Epoch 64/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 9.0069e-04 - val_loss: 0.0138\n",
      "Epoch 65/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.2891e-04 - val_loss: 0.0020\n",
      "Epoch 66/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.4060e-04 - val_loss: 0.0087\n",
      "Epoch 67/300\n",
      "54/54 [==============================] - 2s 38ms/step - loss: 8.4586e-04 - val_loss: 0.0080\n",
      "Epoch 68/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.5312e-04 - val_loss: 0.0049\n",
      "Epoch 69/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.4479e-04 - val_loss: 0.0015\n",
      "Epoch 70/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.5115e-04 - val_loss: 0.0092\n",
      "Epoch 71/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.2217e-04 - val_loss: 0.0106\n",
      "Epoch 72/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.2661e-04 - val_loss: 7.4392e-04\n",
      "Epoch 73/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.1652e-04 - val_loss: 7.6917e-04\n",
      "Epoch 74/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.2865e-04 - val_loss: 0.0016\n",
      "Epoch 75/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.2600e-04 - val_loss: 0.0012\n",
      "Epoch 76/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.3847e-04 - val_loss: 0.0013\n",
      "Epoch 77/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.3020e-04 - val_loss: 0.0074\n",
      "Epoch 78/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.1309e-04 - val_loss: 0.0102\n",
      "Epoch 79/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.2959e-04 - val_loss: 0.0091\n",
      "Epoch 80/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.9560e-04 - val_loss: 0.0025\n",
      "Epoch 81/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.1372e-04 - val_loss: 0.0085\n",
      "Epoch 82/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.4154e-04 - val_loss: 0.0018\n",
      "Epoch 83/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.8740e-04 - val_loss: 0.0089\n",
      "Epoch 84/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.3988e-04 - val_loss: 0.0031\n",
      "Epoch 85/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.5036e-04 - val_loss: 0.0208\n",
      "Epoch 86/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.5497e-04 - val_loss: 0.0018\n",
      "Epoch 87/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.3669e-04 - val_loss: 0.0046\n",
      "Epoch 88/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.4284e-04 - val_loss: 0.0082\n",
      "Epoch 89/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.8185e-04 - val_loss: 0.0100\n",
      "Epoch 90/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.4669e-04 - val_loss: 0.0070\n",
      "Epoch 91/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.1833e-04 - val_loss: 0.0157\n",
      "Epoch 92/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.3179e-04 - val_loss: 0.0037\n",
      "Epoch 93/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.0873e-04 - val_loss: 0.0011\n",
      "Epoch 94/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 8.2383e-04 - val_loss: 0.0054\n",
      "Epoch 95/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.3815e-04 - val_loss: 8.8084e-04\n",
      "Epoch 96/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 8.0788e-04 - val_loss: 0.0237\n",
      "Epoch 97/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 8.3039e-04 - val_loss: 0.0060\n",
      "Epoch 98/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 8.7541e-04 - val_loss: 0.0125\n",
      "Epoch 99/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 8.0973e-04 - val_loss: 0.0028\n",
      "Epoch 100/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 8.3940e-04 - val_loss: 0.0057\n",
      "Epoch 101/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 8.0688e-04 - val_loss: 8.9636e-04\n",
      "Epoch 102/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 8.4138e-04 - val_loss: 0.0038\n",
      "Epoch 102: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor = 'val_loss' , patience = 30 , mode = 'min' , verbose = 1)\n",
    "history = model.fit(btc_train[0] , btc_train[1] , validation_data = btc_val  , batch_size = 512  , epochs =300 , verbose = 1 , callbacks=[earlyStopping])\n",
    "num_epochs = earlyStopping.stopped_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8651e42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "#plt.ylim([0,0.01])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f134e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
