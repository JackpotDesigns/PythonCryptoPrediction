{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac622ed7",
   "metadata": {},
   "source": [
    "<Strong> Develop a TCN model that overfits , then do some regularization , then do some tuning. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44717bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from IPython.display import display, Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error , mean_absolute_percentage_error\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.layers import LSTM , Dense , Dropout , GRU , Concatenate , Flatten , Input , Conv1D , InputLayer , MaxPooling1D\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f7bdf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc = pd.read_csv(\"BTC_1h_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a0817",
   "metadata": {},
   "source": [
    "<Strong> Grabbing the closing price (univariate) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf871789",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_data = df_btc.values[:, 4 ,].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9b282",
   "metadata": {},
   "source": [
    "<Strong> Scaling the data  </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5026d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "percTrain = 70\n",
    "percVal = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b14cf325",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "    \n",
    "onePercent = len(btc_data) // 100\n",
    "numberTraining = onePercent * percTrain\n",
    "\n",
    "reshaped_data = btc_data.reshape(-1,1)\n",
    "\n",
    "#Just scaling on training data otherwise it would be leakage\n",
    "scaler.fit(reshaped_data[:numberTraining])\n",
    "scaled_btc = scaler.transform(reshaped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cb093",
   "metadata": {},
   "source": [
    "<Strong> Hyper-parameters </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "393c0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters that are dependant on the number of layers \n",
    "\n",
    "# Dilation_rate\n",
    "# window_length \n",
    "# kernel_size\n",
    "\n",
    "# The rest of the hyper-parameter\n",
    "\n",
    "# learning_rate\n",
    "# Dense layer size\n",
    "# filters \n",
    "# batch_size\n",
    "\n",
    "window_length = 72\n",
    "dilation_rate = 2\n",
    "kernel_size = 2\n",
    "features = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5850e82f",
   "metadata": {},
   "source": [
    "<Strong> Creating Matrix in Sliding window form <Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c11d0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(elements, window_size):\n",
    "    \n",
    "    data = [] \n",
    "    targets = []\n",
    "    \n",
    "    if len(elements) <= window_size:\n",
    "        return elements\n",
    "    \n",
    "    for i in range(len(elements) - window_size ):\n",
    "        \n",
    "        data.append(elements[i:i+window_size])\n",
    "        targets.append(elements[i+window_size])\n",
    "        \n",
    "    return np.array(data) , np.array(targets)\n",
    "\n",
    "sliding_winda_btc = sliding_window(scaled_btc , window_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33395fb",
   "metadata": {},
   "source": [
    "<Strong> Splitting the data into train , val , test </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b06e1637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data after creating the sliding window data\n",
    "def splitting_train_test(data):\n",
    "        \n",
    "    onePercent = len(data[1]) // 100\n",
    "    \n",
    "    numberTraining = onePercent * percTrain\n",
    "    numberValidation = onePercent * percVal\n",
    "    \n",
    "    trainingData = data[0][:numberTraining] , data[1][:numberTraining]\n",
    "    validationData = data[0][numberTraining : numberTraining + numberValidation] , data[1][numberTraining : numberTraining + numberValidation]\n",
    "    testData = data[0][numberTraining + numberValidation:] , data[1][numberTraining + numberValidation:] \n",
    "    \n",
    "    #Returning tuples of (sliding-window , target_values)\n",
    "    return trainingData , validationData , testData\n",
    "\n",
    "btc_train , btc_val , btc_test = splitting_train_test(sliding_winda_btc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dfcce2",
   "metadata": {},
   "source": [
    "<Strong> The number of layers while changing dilation_base , kernel_size or window_size. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c1cd3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers = 5 kernel size = 2 dilation rate = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 2, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getLayers(dilation_rate , window_size , kernel_size):\n",
    "    \n",
    "    top = (dilation_rate - 1) * (window_size - 1)\n",
    "    bottom = (kernel_size - 1) \n",
    "    \n",
    "    division = (top / bottom) + 1 \n",
    "    log = math.ceil(math.log(division , dilation_rate))\n",
    "    \n",
    "    \n",
    "    # This inequality must hold true for full coverage\n",
    "    \n",
    "    first = 1 + (kernel_size - 1)\n",
    "    second = (dilation_rate ** log ) - 1\n",
    "    third = dilation_rate - 1\n",
    "    \n",
    "    inequality = (second / third) * first\n",
    "    \n",
    "    if ( (kernel_size < dilation_rate) or (inequality < window_size) ):\n",
    "        print(\"not going to have full coverage\")\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        print(\"layers =\" , log , \"kernel size =\" , kernel_size , \"dilation rate =\" , dilation_rate )\n",
    "        return log , dilation_rate , kernel_size\n",
    "\n",
    "getLayers(2 , 24 , 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13327db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelFiveLayers(hp):\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate' , values = [0.002 , 0.004 , 0.006 , 0.008])\n",
    "    hp_dense_layer = hp.Choice('dense_layer' , values = [16 , 32 , 64])\n",
    "    hp_filters = hp.Choice ('filters' , values = [8 , 16 , 32])\n",
    "    hp_dropout = hp.Choice ('dropout' , values = [0.0 , 0.05 , 0.1])\n",
    "\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters= hp_filters, kernel_size=2, activation='relu', input_shape=(window_length, 1), dilation_rate=1 , padding = 'causal'))\n",
    "    model.add(Conv1D(filters= hp_filters, kernel_size=2, activation='relu' , padding = 'causal', dilation_rate=2))\n",
    "    model.add(Conv1D(filters= hp_filters , kernel_size=2, activation='relu' , padding = 'causal' , dilation_rate=4))\n",
    "    model.add(Conv1D(filters= hp_filters , kernel_size=2, activation='relu' , padding = 'causal' , dilation_rate=8))\n",
    "    model.add(Conv1D(filters= hp_filters , kernel_size=2, activation='relu' , padding = 'causal' , dilation_rate=16))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    \n",
    "    model.add(Dropout(hp_dropout))\n",
    "    \n",
    "    model.add(Dense(hp_dense_layer, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    opt = Adam(learning_rate=hp_learning_rate)\n",
    "    model.compile(optimizer=opt , loss = 'mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e625e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_10 (Conv1D)          (None, 72, 8)             24        \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 72, 8)             136       \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 72, 8)             136       \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 72, 8)             136       \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 72, 8)             136       \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                9232      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,817\n",
      "Trainable params: 9,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch (\n",
    "    createModelFiveLayers,\n",
    "    objective = \"val_loss\",\n",
    "    max_trials=25,\n",
    "    executions_per_trial=1,\n",
    "    directory = 'tcn',\n",
    "    project_name='tcn 5 layers 72 window'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b51dbcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 Complete [00h 01m 49s]\n",
      "val_loss: 0.001506519503891468\n",
      "\n",
      "Best val_loss So Far: 0.000559048552531749\n",
      "Total elapsed time: 00h 56m 12s\n",
      "\n",
      "Search: Running Trial #18\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "learning_rate     |0.002             |0.004             \n",
      "dense_layer       |16                |16                \n",
      "filters           |32                |32                \n",
      "dropout           |0.1               |0                 \n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 72, 32)            96        \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 72, 32)            2080      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 72, 32)            2080      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 72, 32)            2080      \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 72, 32)            2080      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                36880     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,313\n",
      "Trainable params: 45,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "54/54 [==============================] - 4s 69ms/step - loss: 0.0085 - val_loss: 0.0654\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 7.3781e-04 - val_loss: 0.0359\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 4s 67ms/step - loss: 6.6860e-04 - val_loss: 0.0354\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 4s 68ms/step - loss: 5.6867e-04 - val_loss: 0.0319\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 4s 69ms/step - loss: 4.7751e-04 - val_loss: 0.0193\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 4s 67ms/step - loss: 3.9164e-04 - val_loss: 0.0344\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 3.5176e-04 - val_loss: 0.0570\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 3.2941e-04 - val_loss: 0.0480\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 2.9493e-04 - val_loss: 0.0303\n",
      "Epoch 10/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 2.6597e-04 - val_loss: 0.0328\n",
      "Epoch 11/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 2.3647e-04 - val_loss: 0.0429\n",
      "Epoch 12/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 2.2372e-04 - val_loss: 0.0159\n",
      "Epoch 13/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 2.0545e-04 - val_loss: 0.0237\n",
      "Epoch 14/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 1.8971e-04 - val_loss: 0.0150\n",
      "Epoch 15/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.6636e-04 - val_loss: 0.0383\n",
      "Epoch 16/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 1.5934e-04 - val_loss: 0.0171\n",
      "Epoch 17/300\n",
      "54/54 [==============================] - 4s 79ms/step - loss: 1.4953e-04 - val_loss: 0.0219\n",
      "Epoch 18/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.6511e-04 - val_loss: 0.0148\n",
      "Epoch 19/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.4134e-04 - val_loss: 0.0184\n",
      "Epoch 20/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 1.3106e-04 - val_loss: 0.0175\n",
      "Epoch 21/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 1.4783e-04 - val_loss: 0.0134\n",
      "Epoch 22/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 1.2334e-04 - val_loss: 0.0256\n",
      "Epoch 23/300\n",
      "54/54 [==============================] - 3s 65ms/step - loss: 1.2590e-04 - val_loss: 0.0342\n",
      "Epoch 24/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.4974e-04 - val_loss: 0.0158\n",
      "Epoch 25/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.2581e-04 - val_loss: 0.0165\n",
      "Epoch 26/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.3662e-04 - val_loss: 0.0192\n",
      "Epoch 27/300\n",
      "54/54 [==============================] - 3s 65ms/step - loss: 1.4656e-04 - val_loss: 0.0260\n",
      "Epoch 28/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.0682e-04 - val_loss: 0.0231\n",
      "Epoch 29/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 9.9075e-05 - val_loss: 0.0222\n",
      "Epoch 30/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.2626e-04 - val_loss: 0.0236\n",
      "Epoch 31/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.0176e-04 - val_loss: 0.0133\n",
      "Epoch 32/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 9.1459e-05 - val_loss: 0.0320\n",
      "Epoch 33/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.0122e-04 - val_loss: 0.0131\n",
      "Epoch 34/300\n",
      "54/54 [==============================] - 4s 79ms/step - loss: 9.2850e-05 - val_loss: 0.0154\n",
      "Epoch 35/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 8.5478e-05 - val_loss: 0.0219\n",
      "Epoch 36/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 9.8769e-05 - val_loss: 0.0179\n",
      "Epoch 37/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.0134e-04 - val_loss: 0.0300\n",
      "Epoch 38/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 9.2766e-05 - val_loss: 0.0134\n",
      "Epoch 39/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 9.8150e-05 - val_loss: 0.0191\n",
      "Epoch 40/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 8.9875e-05 - val_loss: 0.0050\n",
      "Epoch 41/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.1493e-04 - val_loss: 0.0098\n",
      "Epoch 42/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.0473e-04 - val_loss: 0.0093\n",
      "Epoch 43/300\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 7.5420e-05 - val_loss: 0.0186\n",
      "Epoch 44/300\n",
      "54/54 [==============================] - 4s 67ms/step - loss: 8.6304e-05 - val_loss: 0.0117\n",
      "Epoch 45/300\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 9.8416e-05 - val_loss: 0.0052\n",
      "Epoch 46/300\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 9.9710e-05 - val_loss: 0.0224\n",
      "Epoch 47/300\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 7.6732e-05 - val_loss: 0.0224\n",
      "Epoch 48/300\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 7.0888e-05 - val_loss: 0.0114\n",
      "Epoch 49/300\n",
      "54/54 [==============================] - 3s 65ms/step - loss: 6.9673e-05 - val_loss: 0.0091\n",
      "Epoch 50/300\n",
      "54/54 [==============================] - 4s 65ms/step - loss: 9.7087e-05 - val_loss: 0.0146\n",
      "Epoch 51/300\n",
      "54/54 [==============================] - 4s 81ms/step - loss: 9.4649e-05 - val_loss: 0.0121\n",
      "Epoch 52/300\n",
      "54/54 [==============================] - 3s 65ms/step - loss: 6.5266e-05 - val_loss: 0.0114\n",
      "Epoch 53/300\n",
      "54/54 [==============================] - 4s 70ms/step - loss: 7.3660e-05 - val_loss: 0.0263\n",
      "Epoch 54/300\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 8.6509e-05 - val_loss: 0.0105\n",
      "Epoch 55/300\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 9.8668e-05 - val_loss: 0.0071\n",
      "Epoch 56/300\n",
      "54/54 [==============================] - 3s 65ms/step - loss: 6.7060e-05 - val_loss: 0.0174\n",
      "Epoch 57/300\n",
      "54/54 [==============================] - 3s 65ms/step - loss: 8.1215e-05 - val_loss: 0.0062\n",
      "Epoch 58/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.0516e-04 - val_loss: 0.0167\n",
      "Epoch 59/300\n",
      "54/54 [==============================] - 4s 65ms/step - loss: 7.1359e-05 - val_loss: 0.0113\n",
      "Epoch 60/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 6.0639e-05 - val_loss: 0.0053\n",
      "Epoch 61/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 6.4233e-05 - val_loss: 0.0123\n",
      "Epoch 62/300\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 6.3982e-05 - val_loss: 0.0210\n",
      "Epoch 63/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 8.0126e-05 - val_loss: 0.0088\n",
      "Epoch 64/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 6.1096e-05 - val_loss: 0.0045\n",
      "Epoch 65/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 8.5584e-05 - val_loss: 0.0144\n",
      "Epoch 66/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 8.0865e-05 - val_loss: 0.0042\n",
      "Epoch 67/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 7.9664e-05 - val_loss: 0.0095\n",
      "Epoch 68/300\n",
      "54/54 [==============================] - 4s 80ms/step - loss: 7.2779e-05 - val_loss: 0.0095\n",
      "Epoch 69/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 7.8184e-05 - val_loss: 0.0270\n",
      "Epoch 70/300\n",
      "54/54 [==============================] - 3s 65ms/step - loss: 8.7529e-05 - val_loss: 0.0192\n",
      "Epoch 71/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 7.1316e-05 - val_loss: 0.0088\n",
      "Epoch 72/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 6.9402e-05 - val_loss: 0.0068\n",
      "Epoch 73/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 7.1052e-05 - val_loss: 0.0064\n",
      "Epoch 74/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 5.5916e-05 - val_loss: 0.0082\n",
      "Epoch 75/300\n",
      "54/54 [==============================] - 3s 62ms/step - loss: 5.7218e-05 - val_loss: 0.0102\n",
      "Epoch 76/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 8.5165e-05 - val_loss: 0.0076\n",
      "Epoch 77/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 5.9607e-05 - val_loss: 0.0108\n",
      "Epoch 78/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 7.5351e-05 - val_loss: 0.0033\n",
      "Epoch 79/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 1.0305e-04 - val_loss: 0.0081\n",
      "Epoch 80/300\n",
      "54/54 [==============================] - 3s 65ms/step - loss: 5.5332e-05 - val_loss: 0.0079\n",
      "Epoch 81/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 6.3177e-05 - val_loss: 0.0058\n",
      "Epoch 82/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 6.7723e-05 - val_loss: 0.0066\n",
      "Epoch 83/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 8.9288e-05 - val_loss: 0.0077\n",
      "Epoch 84/300\n",
      "54/54 [==============================] - 3s 62ms/step - loss: 5.3022e-05 - val_loss: 0.0046\n",
      "Epoch 85/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 7.0801e-05 - val_loss: 0.0031\n",
      "Epoch 86/300\n",
      "54/54 [==============================] - 4s 81ms/step - loss: 5.9105e-05 - val_loss: 0.0124\n",
      "Epoch 87/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 6.5293e-05 - val_loss: 0.0068\n",
      "Epoch 88/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 5.0520e-05 - val_loss: 0.0138\n",
      "Epoch 89/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 4.9419e-05 - val_loss: 0.0055\n",
      "Epoch 90/300\n",
      "54/54 [==============================] - 4s 65ms/step - loss: 5.9267e-05 - val_loss: 0.0094\n",
      "Epoch 91/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 7.7437e-05 - val_loss: 0.0214\n",
      "Epoch 92/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 6.7011e-05 - val_loss: 0.0050\n",
      "Epoch 93/300\n",
      "54/54 [==============================] - 3s 65ms/step - loss: 6.6821e-05 - val_loss: 0.0164\n",
      "Epoch 94/300\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 5.6097e-05 - val_loss: 0.0059\n",
      "Epoch 95/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 5.2429e-05 - val_loss: 0.0096\n",
      "Epoch 96/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 6.6104e-05 - val_loss: 0.0194\n",
      "Epoch 97/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 5.7430e-05 - val_loss: 0.0131\n",
      "Epoch 98/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 5.5835e-05 - val_loss: 0.0091\n",
      "Epoch 99/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 5.5486e-05 - val_loss: 0.0072\n",
      "Epoch 100/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 6.0224e-05 - val_loss: 0.0195\n",
      "Epoch 101/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 7.2817e-05 - val_loss: 0.0186\n",
      "Epoch 102/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 5.3879e-05 - val_loss: 0.0047\n",
      "Epoch 103/300\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 4.9361e-05 - val_loss: 0.0046\n",
      "Epoch 104/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 5.4286e-05 - val_loss: 0.0092\n",
      "Epoch 105/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 5.1348e-05 - val_loss: 0.0118\n",
      "Epoch 106/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 6.6599e-05 - val_loss: 0.0054\n",
      "Epoch 107/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 9.7007e-05 - val_loss: 0.0118\n",
      "Epoch 108/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 4.6744e-05 - val_loss: 0.0078\n",
      "Epoch 109/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 5.3781e-05 - val_loss: 0.0125\n",
      "Epoch 110/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 6.8952e-05 - val_loss: 0.0017\n",
      "Epoch 111/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 6.1984e-05 - val_loss: 0.0025\n",
      "Epoch 112/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 4.6866e-05 - val_loss: 0.0086\n",
      "Epoch 113/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 4.5237e-05 - val_loss: 0.0065\n",
      "Epoch 114/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 6.1225e-05 - val_loss: 0.0018\n",
      "Epoch 115/300\n",
      "54/54 [==============================] - 3s 65ms/step - loss: 9.6523e-05 - val_loss: 0.0107\n",
      "Epoch 116/300\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 6.0350e-05 - val_loss: 0.0032\n",
      "Epoch 117/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 4.6003e-05 - val_loss: 0.0014\n",
      "Epoch 118/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 5.8552e-05 - val_loss: 0.0036\n",
      "Epoch 119/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 6.6116e-05 - val_loss: 0.0027\n",
      "Epoch 120/300\n",
      "54/54 [==============================] - 4s 79ms/step - loss: 4.4702e-05 - val_loss: 0.0064\n",
      "Epoch 121/300\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 4.6343e-05 - val_loss: 0.0052\n",
      "Epoch 122/300\n",
      "54/54 [==============================] - 4s 65ms/step - loss: 5.3924e-05 - val_loss: 0.0065\n",
      "Epoch 123/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 4.9798e-05 - val_loss: 0.0012\n",
      "Epoch 124/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 5.0161e-05 - val_loss: 0.0023\n",
      "Epoch 125/300\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 4.6214e-05 - val_loss: 0.0049\n",
      "Epoch 126/300\n",
      " 8/54 [===>..........................] - ETA: 2s - loss: 3.8471e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15908/2605350337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbtc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbtc_val\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# objective left unspecified,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(btc_train[0] , btc_train[1] , epochs=300 , validation_data=btc_val , batch_size = 512 , callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=30)] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
