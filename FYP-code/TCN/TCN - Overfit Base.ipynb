{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac622ed7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<Strong> Develop a TCN model that overfits , then do some regularization , then do some tuning. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44717bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop , Adam\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error , mean_absolute_percentage_error\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.layers import LSTM , Dense , Dropout , GRU , Concatenate , Input , Conv1D , InputLayer , MaxPooling1D\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f7bdf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_btc = pd.read_csv(\"../../cryptoData/BTC_1h_data.csv\")\n",
    "df_btc = pd.read_csv(\"BTC_1h_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a0817",
   "metadata": {},
   "source": [
    "<Strong> Grabbing the closing price (univariate) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf871789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43534.54"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing everything but the closing price\n",
    "btc_data = df_btc.values[:, 4 ,].astype(float)\n",
    "\n",
    "btc_data[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9b282",
   "metadata": {},
   "source": [
    "<Strong> Scaling the data  </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5026d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "percTrain = 70\n",
    "percVal = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b14cf325",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "    \n",
    "onePercent = len(btc_data) // 100\n",
    "numberTraining = onePercent * percTrain\n",
    "\n",
    "reshaped_data = btc_data.reshape(-1,1)\n",
    "\n",
    "#Just scaling on training data otherwise it would be leakage\n",
    "scaler.fit(reshaped_data[:numberTraining])\n",
    "scaled_btc = scaler.transform(reshaped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5850e82f",
   "metadata": {},
   "source": [
    "<Strong> Creating Matrix in Sliding window form <Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c11d0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(elements, window_size):\n",
    "    \n",
    "    data = [] \n",
    "    targets = []\n",
    "    \n",
    "    if len(elements) <= window_size:\n",
    "        return elements\n",
    "    \n",
    "    for i in range(len(elements) - window_size ):\n",
    "        \n",
    "        data.append(elements[i:i+window_size])\n",
    "        targets.append(elements[i+window_size])\n",
    "        \n",
    "    return np.array(data) , np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d9b3c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 24 datapoints to predict the 25th\n",
    "\n",
    "window_length = 24\n",
    "dilation_rate = 2\n",
    "kernel_size = 2\n",
    "\n",
    "features = 1\n",
    "\n",
    "sliding_winda_btc = sliding_window(scaled_btc , window_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33395fb",
   "metadata": {},
   "source": [
    "<Strong> Splitting the data into train , val , test </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b06e1637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data after creating the sliding window data\n",
    "def splitting_train_test(data):\n",
    "        \n",
    "    onePercent = len(data[1]) // 100\n",
    "    \n",
    "    numberTraining = onePercent * percTrain\n",
    "    numberValidation = onePercent * percVal\n",
    "    \n",
    "    trainingData = data[0][:numberTraining] , data[1][:numberTraining]\n",
    "    validationData = data[0][numberTraining : numberTraining + numberValidation] , data[1][numberTraining : numberTraining + numberValidation]\n",
    "    testData = data[0][numberTraining + numberValidation:] , data[1][numberTraining + numberValidation:] \n",
    "    \n",
    "    #Returning tuples of (sliding-window , target_values)\n",
    "    return trainingData , validationData , testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fc3e459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27370, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "btc_train , btc_val , btc_test = splitting_train_test(sliding_winda_btc)\n",
    "\n",
    "print(btc_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4081f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters that are dependant on the number of layers \n",
    "\n",
    "# Dilation_rate\n",
    "# window_length \n",
    "# kernel_size\n",
    "\n",
    "# The rest of the hyper-parameter\n",
    "\n",
    "# learning_rate\n",
    "# Dense layer size\n",
    "# filters \n",
    "# batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7d16e",
   "metadata": {},
   "source": [
    "<Strong> The number of layers while changing dilation_base , kernel_size or window_size. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "770c67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayers(dilation_rate , window_size , kernel_size):\n",
    "    \n",
    "    top = (dilation_rate - 1) * (window_size - 1)\n",
    "    bottom = (kernel_size - 1) \n",
    "    \n",
    "    division = (top / bottom) + 1 \n",
    "    log = math.ceil(math.log(division , dilation_rate))\n",
    "    \n",
    "    \n",
    "    # This inequality must hold true for full coverage\n",
    "    \n",
    "    first = 1 + (kernel_size - 1)\n",
    "    second = (dilation_rate ** log ) - 1\n",
    "    third = dilation_rate - 1\n",
    "    \n",
    "    inequality = (second / third) * first\n",
    "    \n",
    "    if ( (kernel_size < dilation_rate) or (inequality < window_size) ):\n",
    "        print(\"not going to have full coverage\")\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        print(\"layers =\" , log , \"kernel size =\" , kernel_size , \"dilation rate =\" , dilation_rate )\n",
    "        return log , dilation_rate , kernel_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50a517a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers = 2 kernel size = 4 dilation rate = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 4, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getLayers(4 , 12 , 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69359a98",
   "metadata": {},
   "source": [
    "<Strong> Below I have created 3 models (5 , 4 , 3 layered TCN).  </Strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5320e8c",
   "metadata": {},
   "source": [
    "<p> The number for the dilation_rate , kernel_size and window_size for each layer where calculated with the getLayers function above. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cef6a8b",
   "metadata": {},
   "source": [
    "<p> Here I am just adjusting necessary componenets. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a40179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelFiveLayers(hp):\n",
    "    \n",
    "    num_layers = 5\n",
    "    dilation = 2\n",
    "\n",
    "    hp_kernel_size = hp.Choice('kernel_size' , values = [2,3,4])\n",
    "    hp_learning_rate = hp.Choice('learning_rate' , values = [0.002 , 0.004 , 0.006 , 0.008 , 0.01])\n",
    "    #hp_dense_layer = hp.Choice('dense_layer' , values = [64 , 128 , 256])\n",
    "    hp_filters = hp.Choice('filters' , values = [32, 64 , 128])\n",
    "    \n",
    "    model1 = models.Sequential()\n",
    "    \n",
    "    # Casual adds padding to the start of input sequence\n",
    "    model1.add(Conv1D(filters=hp_filters, kernel_size=hp_kernel_size, activation='relu', input_shape=(window_length, features), dilation_rate=1 , padding = 'causal'))\n",
    "\n",
    "    #minus one for the base conv1d layer ^\n",
    "    for i in range (1 , num_layers):\n",
    "        \n",
    "        # For full coverage we need 4 layers \n",
    "        model1.add(Conv1D(filters=hp_filters, kernel_size=hp_kernel_size, activation='relu' , padding = 'causal', dilation_rate= dilation**i))\n",
    "\n",
    "    #model1.add(Dense(hp_dense_layer, activation='relu'))\n",
    "\n",
    "    model1.add(Dense(1))\n",
    "\n",
    "    model1.summary()\n",
    "    \n",
    "    opt = Adam(learning_rate=hp_learning_rate)\n",
    "    model1.compile(optimizer=opt , loss = 'mse')\n",
    "    \n",
    "    return model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df85eddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 24, 32)            96        \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 24, 32)            2080      \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 24, 32)            2080      \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 24, 32)            2080      \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 24, 32)            2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24, 1)             33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,449\n",
      "Trainable params: 8,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tunerFiveLayers = RandomSearch (\n",
    "    createModelFiveLayers,\n",
    "    objective = \"val_loss\",\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    directory = 'tcn',\n",
    "    project_name='tcn_five_layers'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dad3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "kernel_size       |2                 |?                 \n",
      "learning_rate     |0.008             |?                 \n",
      "filters           |128               |?                 \n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 24, 128)           384       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 24, 128)           32896     \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 24, 128)           32896     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 24, 128)           32896     \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 24, 128)           32896     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24, 1)             129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,097\n",
      "Trainable params: 132,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "54/54 [==============================] - 13s 230ms/step - loss: 0.0384 - val_loss: 0.0788\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 12s 228ms/step - loss: 4.7177e-04 - val_loss: 0.0083\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 11s 209ms/step - loss: 3.3607e-04 - val_loss: 0.0090\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 11s 206ms/step - loss: 3.1918e-04 - val_loss: 0.0096\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 11s 212ms/step - loss: 3.0938e-04 - val_loss: 0.0117\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 11s 197ms/step - loss: 3.1489e-04 - val_loss: 0.0072\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 11s 198ms/step - loss: 3.2840e-04 - val_loss: 0.0076\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 11s 196ms/step - loss: 3.2353e-04 - val_loss: 0.0111\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 11s 196ms/step - loss: 3.4089e-04 - val_loss: 0.0081\n",
      "Epoch 10/300\n",
      "54/54 [==============================] - 11s 202ms/step - loss: 3.0941e-04 - val_loss: 0.0126\n",
      "Epoch 11/300\n",
      "54/54 [==============================] - 11s 197ms/step - loss: 3.1372e-04 - val_loss: 0.0223\n",
      "Epoch 12/300\n",
      "54/54 [==============================] - 10s 193ms/step - loss: 3.6248e-04 - val_loss: 0.0114\n",
      "Epoch 13/300\n",
      "54/54 [==============================] - 10s 193ms/step - loss: 3.0324e-04 - val_loss: 0.0076\n",
      "Epoch 14/300\n",
      "54/54 [==============================] - 10s 194ms/step - loss: 3.3914e-04 - val_loss: 0.0093\n",
      "Epoch 15/300\n",
      "54/54 [==============================] - 10s 193ms/step - loss: 3.1936e-04 - val_loss: 0.0114\n",
      "Epoch 16/300\n",
      "54/54 [==============================] - 10s 192ms/step - loss: 3.3018e-04 - val_loss: 0.0104\n",
      "Epoch 17/300\n",
      "54/54 [==============================] - 10s 194ms/step - loss: 3.1690e-04 - val_loss: 0.0172\n",
      "Epoch 18/300\n",
      "54/54 [==============================] - 11s 200ms/step - loss: 3.0262e-04 - val_loss: 0.0093\n",
      "Epoch 19/300\n",
      "54/54 [==============================] - 10s 190ms/step - loss: 3.1577e-04 - val_loss: 0.0096\n",
      "Epoch 20/300\n",
      "54/54 [==============================] - 523s 10s/step - loss: 3.2192e-04 - val_loss: 0.0105\n",
      "Epoch 21/300\n",
      " 4/54 [=>............................] - ETA: 9s - loss: 2.7962e-04 "
     ]
    }
   ],
   "source": [
    "tunerFiveLayers.search(btc_train[0] , btc_train[1] , epochs=300 , validation_data=btc_val , batch_size = 512, callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=30)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2b7e2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelFourLayers(hp):\n",
    "    \n",
    "    num_layers = 4\n",
    "    \n",
    "    dilation=2\n",
    "    hp_kernel_size = hp.Choice('kernel_size' , values = [3,4,5])\n",
    "    hp_learning_rate = hp.Choice('learning_rate' , values = [0.002 , 0.004 , 0.006 , 0.008 , 0.01])\n",
    "    hp_dense_layer = hp.Choice('dense_layer' , values = [64 , 128 , 256])\n",
    "\n",
    "    \n",
    "    model1 = models.Sequential()\n",
    "    \n",
    "    # Casual adds padding to the start of input sequence\n",
    "    model1.add(Conv1D(filters=32, kernel_size=hp_kernel_size, activation='relu', input_shape=(window_length, features), dilation_rate=1 , padding = 'causal'))\n",
    "\n",
    "    #minus one for the base conv1d layer ^\n",
    "    for i in range (1 , num_layers):\n",
    "        \n",
    "        # For full coverage we need 4 layers \n",
    "        model1.add(Conv1D(filters=32, kernel_size=hp_kernel_size, activation='relu' , padding = 'causal', dilation_rate= dilation**i))\n",
    "\n",
    "    #model1.add(Dense(hp_dense_layer, activation='relu'))\n",
    "\n",
    "    model1.add(Dense(1))\n",
    "\n",
    "    model1.summary()\n",
    "    \n",
    "    opt = Adam(learning_rate=hp_learning_rate)\n",
    "    model1.compile(optimizer=opt , loss = 'mse')\n",
    "    \n",
    "    return model1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d2cb8f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 24, 32)            128       \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 24, 32)            3104      \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 24, 32)            3104      \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 24, 32)            3104      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 24, 1)             33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,473\n",
      "Trainable params: 9,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tunerFourLayers = RandomSearch (\n",
    "    createModelFourLayers,\n",
    "    objective = \"val_loss\",\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    directory = 'tcn',\n",
    "    project_name='tcn_four_layers'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0f532440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 02m 25s]\n",
      "val_loss: 0.009956913068890572\n",
      "\n",
      "Best val_loss So Far: 0.006215453613549471\n",
      "Total elapsed time: 00h 15m 16s\n",
      "\n",
      "Search: Running Trial #7\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "kernel_size       |3                 |3                 \n",
      "learning_rate     |0.002             |0.006             \n",
      "dense_layer       |64                |256               \n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 24, 32)            128       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 24, 32)            3104      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 24, 32)            3104      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 24, 32)            3104      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24, 1)             33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,473\n",
      "Trainable params: 9,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 0.0174 - val_loss: 0.1929\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 7.7298e-04 - val_loss: 0.0534\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 3.4838e-04 - val_loss: 0.0392\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 3.4264e-04 - val_loss: 0.0362\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 2s 36ms/step - loss: 3.3265e-04 - val_loss: 0.0351\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 3.2300e-04 - val_loss: 0.0365\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 2s 32ms/step - loss: 3.1887e-04 - val_loss: 0.0317\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 2s 33ms/step - loss: 3.2161e-04 - val_loss: 0.0335\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 2s 41ms/step - loss: 3.3299e-04 - val_loss: 0.0270\n",
      "Epoch 10/300\n",
      "54/54 [==============================] - 2s 40ms/step - loss: 3.2406e-04 - val_loss: 0.0301\n",
      "Epoch 11/300\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 3.2571e-04 - val_loss: 0.0350\n",
      "Epoch 12/300\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 3.1084e-04 - val_loss: 0.0338\n",
      "Epoch 13/300\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 3.1333e-04 - val_loss: 0.0329\n",
      "Epoch 14/300\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 3.1043e-04 - val_loss: 0.0305\n",
      "Epoch 15/300\n",
      " 9/54 [====>.........................] - ETA: 1s - loss: 3.3158e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cv/9wyhthmx21d7ylr5zx17lfmr0000gn/T/ipykernel_70118/2146501925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtunerFourLayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbtc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbtc_val\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# objective left unspecified,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tunerFourLayers.search(btc_train[0] , btc_train[1] , epochs=300 , validation_data=btc_val , batch_size = 512, callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=30)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e22a0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelThreeLayers(hp):\n",
    "    \n",
    "    num_layers = 3\n",
    "    \n",
    "    hp_dilation_rate = hp.Choice('dilation_rate', values = [2] ) \n",
    "    hp_kernel_size = hp.Choice('kernel_size' , values = [3,4,5])\n",
    "    hp_learning_rate = hp.Choice('learning_rate' , values = [0.002 , 0.004 , 0.006 , 0.008 , 0.01])\n",
    "    #hp_dense_layer = hp.Choice('dense_layer' , values = [64 , 128 , 256])\n",
    "\n",
    "    \n",
    "    model1 = models.Sequential()\n",
    "    \n",
    "    # Casual adds padding to the start of input sequence\n",
    "    model1.add(Conv1D(filters=32, kernel_size=hp_kernel_size, activation='relu', input_shape=(window_length, features), dilation_rate=1 , padding = 'causal'))\n",
    "\n",
    "    #minus one for the base conv1d layer ^\n",
    "    for i in range (1 , num_layers):\n",
    "        \n",
    "        # For full coverage we need 4 layers \n",
    "        model1.add(Conv1D(filters=32, kernel_size=hp_kernel_size, activation='relu' , padding = 'causal', dilation_rate= 2**i))\n",
    "\n",
    "    #model1.add(Dense(hp_dense_layer, activation='relu'))\n",
    "\n",
    "    model1.add(Dense(1))\n",
    "\n",
    "    model1.summary()\n",
    "    \n",
    "    opt = Adam(learning_rate=hp_learning_rate)\n",
    "    model1.compile(optimizer=opt , loss = 'mse')\n",
    "    \n",
    "    return model1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "40cda79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 24, 32)            128       \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 24, 32)            3104      \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 24, 32)            3104      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24, 1)             33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,369\n",
      "Trainable params: 6,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tunerThreeLayers = RandomSearch (\n",
    "    createModelThreeLayers,\n",
    "    objective = \"val_loss\",\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    directory = 'tcn',\n",
    "    project_name='tcn_three_layers'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdf211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 03s]\n",
      "val_loss: 0.0067231738939881325\n",
      "\n",
      "Best val_loss So Far: 0.0062348488718271255\n",
      "Total elapsed time: 00h 09m 30s\n",
      "\n",
      "Search: Running Trial #6\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "dilation_rate     |2                 |2                 \n",
      "kernel_size       |3                 |4                 \n",
      "learning_rate     |0.006             |0.004             \n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 24, 32)            128       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 24, 32)            3104      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 24, 32)            3104      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24, 1)             33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,369\n",
      "Trainable params: 6,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "54/54 [==============================] - 2s 23ms/step - loss: 0.0095 - val_loss: 0.0077\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 3.7194e-04 - val_loss: 0.0080\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 3.3952e-04 - val_loss: 0.0086\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 3.3094e-04 - val_loss: 0.0096\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 3.2777e-04 - val_loss: 0.0093\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 3.3373e-04 - val_loss: 0.0097\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 3.3633e-04 - val_loss: 0.0107\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 3.2095e-04 - val_loss: 0.0092\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 3.3613e-04 - val_loss: 0.0090\n",
      "Epoch 10/300\n",
      "49/54 [==========================>...] - ETA: 0s - loss: 3.1476e-04"
     ]
    }
   ],
   "source": [
    "tunerThreeLayers.search(btc_train[0] , btc_train[1] , epochs=300 , validation_data=btc_val , batch_size = 512 , callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=30)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "945e8820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "54/54 [==============================] - 3s 47ms/step - loss: 0.0251 - val_loss: 0.2865\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 2s 41ms/step - loss: 0.0011 - val_loss: 0.0555\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 2s 41ms/step - loss: 3.7039e-04 - val_loss: 0.0310\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 3.2776e-04 - val_loss: 0.0276\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 3.2388e-04 - val_loss: 0.0206\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 2s 44ms/step - loss: 3.1610e-04 - val_loss: 0.0197\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 3.0893e-04 - val_loss: 0.0194\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 2s 41ms/step - loss: 3.0680e-04 - val_loss: 0.0202\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 2s 44ms/step - loss: 2.9869e-04 - val_loss: 0.0190\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 2.9899e-04 - val_loss: 0.0205\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 2.9642e-04 - val_loss: 0.0190\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 2.9700e-04 - val_loss: 0.0205\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 2.9841e-04 - val_loss: 0.0181\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 3.0453e-04 - val_loss: 0.0182\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 2.9286e-04 - val_loss: 0.0160\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 2.8869e-04 - val_loss: 0.0153\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 2.9881e-04 - val_loss: 0.0169\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 2s 45ms/step - loss: 3.1348e-04 - val_loss: 0.0159\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 2s 45ms/step - loss: 3.0576e-04 - val_loss: 0.0182\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 2.9586e-04 - val_loss: 0.0206\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 2.9489e-04 - val_loss: 0.0179\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 2s 45ms/step - loss: 2.9335e-04 - val_loss: 0.0219\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 2s 42ms/step - loss: 3.0054e-04 - val_loss: 0.0171\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 3s 46ms/step - loss: 2.8919e-04 - val_loss: 0.0152\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 3.0936e-04 - val_loss: 0.0146\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 3s 50ms/step - loss: 3.0158e-04 - val_loss: 0.0152\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 3s 47ms/step - loss: 2.9473e-04 - val_loss: 0.0157\n",
      "Epoch 28/30\n",
      " 7/54 [==>...........................] - ETA: 2s - loss: 3.1344e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cv/9wyhthmx21d7ylr5zx17lfmr0000gn/T/ipykernel_69479/3750286152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbtc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbtc_val\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model1.fit(btc_train[0] , btc_train[1] , validation_data = btc_val  , batch_size = 512  , epochs =30 , verbose = 1 ,callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=30)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0f00e6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "#plt.ylim([0,0.01])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef8181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
