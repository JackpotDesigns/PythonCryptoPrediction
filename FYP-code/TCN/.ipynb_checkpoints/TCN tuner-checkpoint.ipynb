{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "434fdab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop , Adam\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error , mean_absolute_percentage_error\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.layers import LSTM , Dense , Dropout , GRU , Concatenate , Input , Conv1D , InputLayer\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3969872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_btc = pd.read_csv(\"../../cryptoData/BTC_1h_data.csv\")\n",
    "df_btc = pd.read_csv(\"../../cryptoData/BTC_1h_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b972036",
   "metadata": {},
   "source": [
    "<Strong> Grabbing the closing price (univariate) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b18a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43534.54"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing everything but the closing price\n",
    "btc_data = df_btc.values[:, 4 ,].astype(float)\n",
    "\n",
    "btc_data[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518c920",
   "metadata": {},
   "source": [
    "<Strong> Scaling the data  </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a041ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "percTrain = 70\n",
    "percVal = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "544cffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "    \n",
    "onePercent = len(btc_data) // 100\n",
    "numberTraining = onePercent * percTrain\n",
    "\n",
    "reshaped_data = btc_data.reshape(-1,1)\n",
    "\n",
    "#Just scaling on training data otherwise it would be leakage\n",
    "scaler.fit(reshaped_data[:numberTraining])\n",
    "scaled_btc = scaler.transform(reshaped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5babd96c",
   "metadata": {},
   "source": [
    "<Strong> Creating Matrix in Sliding window form <Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0467d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(elements, window_size):\n",
    "    \n",
    "    data = [] \n",
    "    targets = []\n",
    "    \n",
    "    if len(elements) <= window_size:\n",
    "        return elements\n",
    "    \n",
    "    for i in range(len(elements) - window_size ):\n",
    "        \n",
    "        data.append(elements[i:i+window_size])\n",
    "        targets.append(elements[i+window_size])\n",
    "        \n",
    "    return np.array(data) , np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7bec6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 24 datapoints to predict the 25th\n",
    "\n",
    "window_length = 24\n",
    "features = 1\n",
    "\n",
    "sliding_winda_btc = sliding_window(scaled_btc , window_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3951e0",
   "metadata": {},
   "source": [
    "<Strong> Splitting the data into train , val , test </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ad5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data after creating the sliding window data\n",
    "def splitting_train_test(data):\n",
    "        \n",
    "    onePercent = len(data[1]) // 100\n",
    "    \n",
    "    numberTraining = onePercent * percTrain\n",
    "    numberValidation = onePercent * percVal\n",
    "    \n",
    "    trainingData = data[0][:numberTraining] , data[1][:numberTraining]\n",
    "    validationData = data[0][numberTraining : numberTraining + numberValidation] , data[1][numberTraining : numberTraining + numberValidation]\n",
    "    testData = data[0][numberTraining + numberValidation:] , data[1][numberTraining + numberValidation:] \n",
    "    \n",
    "    #Returning tuples of (sliding-window , target_values)\n",
    "    return trainingData , validationData , testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a3d40b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27370, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "btc_train , btc_val , btc_test = splitting_train_test(sliding_winda_btc)\n",
    "\n",
    "print(btc_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9773fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "\n",
    "# How many hidden layers we should have \n",
    "# Learning rate\n",
    "# Kernel Size\n",
    "# Window Size\n",
    "#Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf28b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=hp_num_filters, kernel_size=3, activation='relu', input_shape=(window_length, 1), dilation_rate=dilations , padding = 'causal'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    opt = Adam(learning_rate=hp_dense_learning_rate)\n",
    "    model.compile(optimizer = opt , loss = 'mse')\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d33c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function build_model at 0x7f995dc80d08>\n"
     ]
    }
   ],
   "source": [
    "oi = build_model\n",
    "\n",
    "\n",
    "print(oi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "012a7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    hp_dense_learning_rate = hp.Choice('learning_rate', values = [0.002 , 0.004 , 0.006 , 0.008 , 0.01] )\n",
    "    hp_num_layers = hp.Int('num_layers', 2 , 10)   \n",
    "    hp_num_filters = hp.Choice('filters' , values = [32 , 64 , 128])\n",
    "    \n",
    "    dilations = 1\n",
    "    \n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(Conv1D(filters=hp_num_filters, kernel_size=3, activation='relu', input_shape=(window_length, 1), dilation_rate=dilations , padding = 'causal'))\n",
    "    \n",
    "    for i in range (hp_num_layers):\n",
    "        \n",
    "        dilations = dilations * 2\n",
    "        \n",
    "        print(dilations)\n",
    "        \n",
    "        model.add(Conv1D(filters=hp_num_filters, kernel_size=3, activation='relu', dilation_rate=dilations , padding = 'causal'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    opt = Adam(learning_rate=hp_dense_learning_rate)\n",
    "    model.compile(optimizer=opt , loss = 'mse')\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "694ad881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tcn/tcn_layers_learningrate/oracle.json\n",
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 12:19:58.438029: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch (\n",
    "    build_model,\n",
    "    objective = \"val_loss\",\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    directory = 'tcn',\n",
    "    project_name='tcn_layers_learningrate'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08d3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "learning_rate     |0.006             |?                 \n",
      "num_layers        |18                |?                 \n",
      "filters           |128               |?                 \n",
      "\n",
      "2\n",
      "4\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "4096\n",
      "8192\n",
      "16384\n",
      "32768\n",
      "65536\n",
      "131072\n",
      "262144\n",
      "Epoch 1/300\n"
     ]
    }
   ],
   "source": [
    "tuner.search(btc_train[0] , btc_train[1] , epochs=300 , validation_data=btc_val , batch_size = 512 ,  callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=30)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bea2600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 24, 4)             16        \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 24, 4)             52        \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 24, 4)             52        \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 24, 4)             52        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24, 1)             5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177\n",
      "Trainable params: 177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Full Converage = 1 + (kernel_size-1) . dilation_base^n - 1 / dilation_base - 1 >= l\n",
    "# Number of required layers = log (dilation_base) ( ((input_length - 1) . (dilation_base - 1) / (k - 1) ) + 1 )\n",
    "# Padding for each layer dilation_base ^ layers below our current . (kernel_size - 1) below = input\n",
    "\n",
    "# For full coverage we need 4 layers (we are using a base of 2)\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Casual adds padding to the start of input sequence\n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='relu', input_shape=(window_length, 1), dilation_rate=1 , padding = 'causal'))\n",
    "\n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='relu' , padding = 'causal', dilation_rate=2))\n",
    "\n",
    "# For full coverage we need 4 layers \n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='relu' , padding = 'causal' , dilation_rate=4))\n",
    "\n",
    "# For full coverage we need 4 layers \n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='relu' , padding = 'causal', dilation_rate= 8))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c45655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(0.008)\n",
    "model.compile(optimizer=opt , loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53f5d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor = 'val_loss' , patience = 30 , mode = 'min' , verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5a2f48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "54/54 [==============================] - 2s 17ms/step - loss: 0.0483 - val_loss: 3.7751\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0262 - val_loss: 3.7775\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0262 - val_loss: 3.7843\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0262 - val_loss: 3.7815\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0262 - val_loss: 3.7781\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 0.0262 - val_loss: 3.7808\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0261 - val_loss: 3.7969\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.0262 - val_loss: 3.7855\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0262 - val_loss: 3.7933\n",
      "Epoch 10/300\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0262 - val_loss: 3.7781\n",
      "Epoch 11/300\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0262 - val_loss: 3.7765\n",
      "Epoch 12/300\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 0.0262 - val_loss: 3.7701\n",
      "Epoch 13/300\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 0.0262 - val_loss: 3.7770\n",
      "Epoch 14/300\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0262 - val_loss: 3.7783\n",
      "Epoch 15/300\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0262 - val_loss: 3.7867\n",
      "Epoch 16/300\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0262 - val_loss: 3.7722\n",
      "Epoch 17/300\n",
      "51/54 [===========================>..] - ETA: 0s - loss: 0.0262"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cv/9wyhthmx21d7ylr5zx17lfmr0000gn/T/ipykernel_25809/26540063.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbtc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbtc_val\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlyStopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearlyStopping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(btc_train[0] , btc_train[1] , validation_data = btc_val  , batch_size = 512  , epochs =300 , verbose = 1 , callbacks=[earlyStopping])\n",
    "\n",
    "num_epochs = earlyStopping.stopped_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7bf128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c231d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
