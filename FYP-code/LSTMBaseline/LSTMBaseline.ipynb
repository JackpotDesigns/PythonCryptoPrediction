{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4c3eeb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error , mean_absolute_percentage_error\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.layers import LSTM , Dense , Dropout , GRU , Concatenate , Input , Conv1D , InputLayer\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2e01f",
   "metadata": {},
   "source": [
    "<Strong> Grabbing the data from stored files (originally pulled from Binance) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a4e8c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_btc = pd.read_csv(\"../../cryptoData/BTC_1h_data.csv\")\n",
    "df_xrp = pd.read_csv(\"XRP_1h_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fd98c9",
   "metadata": {},
   "source": [
    "<Strong> Grabbing the closing price (univariate) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c41b085c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8216"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing everything but the closing price\n",
    "xrp_data = df_xrp.values[:, 4 ,].astype(float)\n",
    "\n",
    "xrp_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1249b0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33017"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xrp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ec535",
   "metadata": {},
   "source": [
    "<Strong> Scaling the data  </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f38b5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "percTrain = 70\n",
    "percVal = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "352daf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "    \n",
    "onePercent = len(xrp_data) // 100\n",
    "numberTraining = onePercent * percTrain\n",
    "\n",
    "reshaped_data = xrp_data.reshape(-1,1)\n",
    "\n",
    "#Just scaling on training data otherwise it would be leakage\n",
    "scaler.fit(reshaped_data[:numberTraining])\n",
    "scaled_xrp = scaler.transform(reshaped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f199f39",
   "metadata": {},
   "source": [
    "<Strong> Creating Matrix in Sliding window form <Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a2704b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(elements, window_size):\n",
    "    \n",
    "    data = [] \n",
    "    targets = []\n",
    "    \n",
    "    if len(elements) <= window_size:\n",
    "        return elements\n",
    "    \n",
    "    for i in range(len(elements) - window_size ):\n",
    "        \n",
    "        data.append(elements[i:i+window_size])\n",
    "        targets.append(elements[i+window_size])\n",
    "        \n",
    "    return np.array(data) , np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "437368be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 24 datapoints to predict the 25th\n",
    "\n",
    "window_length = 24\n",
    "features = 1\n",
    "\n",
    "sliding_winda_xrp = sliding_window(scaled_xrp , window_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dda094",
   "metadata": {},
   "source": [
    "<Strong> Splitting the data after we create Sliding Window matrix (more data) </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5cda109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data after creating the sliding window data\n",
    "def splitting_train_test(data):\n",
    "        \n",
    "    onePercent = len(data[1]) // 100\n",
    "    \n",
    "    numberTraining = onePercent * percTrain\n",
    "    numberValidation = onePercent * percVal\n",
    "    \n",
    "    trainingData = data[0][:numberTraining] , data[1][:numberTraining]\n",
    "    validationData = data[0][numberTraining : numberTraining + numberValidation] , data[1][numberTraining : numberTraining + numberValidation]\n",
    "    testData = data[0][numberTraining + numberValidation:] , data[1][numberTraining + numberValidation:] \n",
    "    \n",
    "    #Returning tuples of (sliding-window , target_values)\n",
    "    return trainingData , validationData , testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "181772eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23030, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshaping the data so we can use min-max a\n",
    "xrp_train , xrp_val , xrp_test = splitting_train_test(sliding_winda_xrp)\n",
    "\n",
    "print(xrp_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570096d2",
   "metadata": {},
   "source": [
    "<Strong> create the model. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6d552421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 24, 1)]           0         \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 24, 30)            3840      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 24, 30)            0         \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 50)                16200     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                3264      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,369\n",
      "Trainable params: 23,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (window_length , features) )\n",
    "\n",
    "x = LSTM(30, return_sequences = True)(inputs)\n",
    "x = Dropout(0.05)(x)\n",
    "x = LSTM(50)(x)\n",
    "x = Dense(units = 64 ,activation='relu')(x)\n",
    "x = Dense(units = 1)(x) \n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs= x)\n",
    "model.summary()\n",
    "plot_model(model)\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt , loss = 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1716ce",
   "metadata": {},
   "source": [
    "<Strong> Creating a callback to avail of early stopping </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "727bfbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor = 'val_loss' , patience = 30 , mode = 'min' , verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f690ace",
   "metadata": {},
   "source": [
    "<Strong> Training the model and storing the epoch training stopped on </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8532e186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "45/45 [==============================] - 4s 23ms/step - loss: 0.0115 - val_loss: 0.0143\n",
      "Epoch 2/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 2.3759e-04 - val_loss: 0.0277\n",
      "Epoch 3/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.8499e-04 - val_loss: 0.0260\n",
      "Epoch 4/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.8063e-04 - val_loss: 0.0256\n",
      "Epoch 5/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.7768e-04 - val_loss: 0.0233\n",
      "Epoch 6/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.7557e-04 - val_loss: 0.0231\n",
      "Epoch 7/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.6782e-04 - val_loss: 0.0199\n",
      "Epoch 8/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.6773e-04 - val_loss: 0.0204\n",
      "Epoch 9/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.6195e-04 - val_loss: 0.0179\n",
      "Epoch 10/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.5832e-04 - val_loss: 0.0171\n",
      "Epoch 11/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.5890e-04 - val_loss: 0.0141\n",
      "Epoch 12/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.5352e-04 - val_loss: 0.0137\n",
      "Epoch 13/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.4958e-04 - val_loss: 0.0130\n",
      "Epoch 14/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.4595e-04 - val_loss: 0.0121\n",
      "Epoch 15/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 1.4371e-04 - val_loss: 0.0115\n",
      "Epoch 16/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.3836e-04 - val_loss: 0.0109\n",
      "Epoch 17/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.3112e-04 - val_loss: 0.0095\n",
      "Epoch 18/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.2845e-04 - val_loss: 0.0083\n",
      "Epoch 19/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.2354e-04 - val_loss: 0.0071\n",
      "Epoch 20/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.2995e-04 - val_loss: 0.0054\n",
      "Epoch 21/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.2118e-04 - val_loss: 0.0051\n",
      "Epoch 22/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.2057e-04 - val_loss: 0.0052\n",
      "Epoch 23/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.1579e-04 - val_loss: 0.0047\n",
      "Epoch 24/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.1020e-04 - val_loss: 0.0034\n",
      "Epoch 25/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.1254e-04 - val_loss: 0.0030\n",
      "Epoch 26/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.1164e-04 - val_loss: 0.0034\n",
      "Epoch 27/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0620e-04 - val_loss: 0.0028\n",
      "Epoch 28/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0622e-04 - val_loss: 0.0027\n",
      "Epoch 29/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0654e-04 - val_loss: 0.0022\n",
      "Epoch 30/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0625e-04 - val_loss: 0.0020\n",
      "Epoch 31/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0486e-04 - val_loss: 0.0023\n",
      "Epoch 32/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0573e-04 - val_loss: 0.0027\n",
      "Epoch 33/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.5275e-05 - val_loss: 0.0024\n",
      "Epoch 34/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.5677e-05 - val_loss: 0.0020\n",
      "Epoch 35/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0088e-04 - val_loss: 0.0016\n",
      "Epoch 36/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.8851e-05 - val_loss: 0.0020\n",
      "Epoch 37/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.6509e-05 - val_loss: 0.0020\n",
      "Epoch 38/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.9991e-05 - val_loss: 0.0019\n",
      "Epoch 39/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.4023e-05 - val_loss: 0.0016\n",
      "Epoch 40/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 1.0160e-04 - val_loss: 0.0019\n",
      "Epoch 41/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.7546e-05 - val_loss: 0.0022\n",
      "Epoch 42/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 9.6282e-05 - val_loss: 0.0023\n",
      "Epoch 43/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 8.6880e-05 - val_loss: 0.0015\n",
      "Epoch 44/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 9.2038e-05 - val_loss: 0.0016\n",
      "Epoch 45/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.9351e-05 - val_loss: 0.0016\n",
      "Epoch 46/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 8.4856e-05 - val_loss: 0.0017\n",
      "Epoch 47/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 8.4124e-05 - val_loss: 0.0021\n",
      "Epoch 48/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.5728e-05 - val_loss: 0.0013\n",
      "Epoch 49/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.4455e-05 - val_loss: 0.0016\n",
      "Epoch 50/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.1490e-05 - val_loss: 0.0014\n",
      "Epoch 51/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.7422e-05 - val_loss: 0.0015\n",
      "Epoch 52/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.7832e-05 - val_loss: 0.0012\n",
      "Epoch 53/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.0720e-05 - val_loss: 0.0014\n",
      "Epoch 54/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.8686e-05 - val_loss: 0.0013\n",
      "Epoch 55/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 8.0204e-05 - val_loss: 0.0012\n",
      "Epoch 56/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.7310e-05 - val_loss: 0.0012\n",
      "Epoch 57/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.7802e-05 - val_loss: 0.0012\n",
      "Epoch 58/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 7.5408e-05 - val_loss: 0.0012\n",
      "Epoch 59/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 7.6803e-05 - val_loss: 0.0013\n",
      "Epoch 60/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 7.3235e-05 - val_loss: 0.0011\n",
      "Epoch 61/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 7.0890e-05 - val_loss: 0.0012\n",
      "Epoch 62/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.0734e-05 - val_loss: 0.0011\n",
      "Epoch 63/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 7.0440e-05 - val_loss: 0.0012\n",
      "Epoch 64/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.7469e-05 - val_loss: 0.0011\n",
      "Epoch 65/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.7092e-05 - val_loss: 0.0016\n",
      "Epoch 66/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.9612e-05 - val_loss: 0.0010\n",
      "Epoch 67/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 7.2348e-05 - val_loss: 0.0012\n",
      "Epoch 68/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.9963e-05 - val_loss: 9.4113e-04\n",
      "Epoch 69/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.7173e-05 - val_loss: 9.0643e-04\n",
      "Epoch 70/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.5563e-05 - val_loss: 9.7180e-04\n",
      "Epoch 71/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.4837e-05 - val_loss: 0.0011\n",
      "Epoch 72/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.8102e-05 - val_loss: 0.0010\n",
      "Epoch 73/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.2688e-05 - val_loss: 9.5815e-04\n",
      "Epoch 74/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.8569e-05 - val_loss: 8.1996e-04\n",
      "Epoch 75/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.4841e-05 - val_loss: 7.8654e-04\n",
      "Epoch 76/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.5206e-05 - val_loss: 0.0010\n",
      "Epoch 77/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 7.0333e-05 - val_loss: 0.0012\n",
      "Epoch 78/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.2904e-05 - val_loss: 8.5705e-04\n",
      "Epoch 79/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.7460e-05 - val_loss: 7.7659e-04\n",
      "Epoch 80/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.9605e-05 - val_loss: 6.7580e-04\n",
      "Epoch 81/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.9587e-05 - val_loss: 6.6144e-04\n",
      "Epoch 82/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.1982e-05 - val_loss: 7.4942e-04\n",
      "Epoch 83/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.1340e-05 - val_loss: 8.2051e-04\n",
      "Epoch 84/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.4278e-05 - val_loss: 6.8332e-04\n",
      "Epoch 85/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.9236e-05 - val_loss: 8.9164e-04\n",
      "Epoch 86/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.7495e-05 - val_loss: 6.3719e-04\n",
      "Epoch 87/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.6359e-05 - val_loss: 6.5307e-04\n",
      "Epoch 88/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.4684e-05 - val_loss: 6.4961e-04\n",
      "Epoch 89/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.5385e-05 - val_loss: 6.8244e-04\n",
      "Epoch 90/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.5099e-05 - val_loss: 6.3046e-04\n",
      "Epoch 91/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.0616e-05 - val_loss: 5.9207e-04\n",
      "Epoch 92/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.4890e-05 - val_loss: 5.7969e-04\n",
      "Epoch 93/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.5655e-05 - val_loss: 5.5903e-04\n",
      "Epoch 94/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.0433e-05 - val_loss: 5.6746e-04\n",
      "Epoch 95/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.7882e-05 - val_loss: 6.9781e-04\n",
      "Epoch 96/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.5587e-05 - val_loss: 5.5434e-04\n",
      "Epoch 97/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.5110e-05 - val_loss: 5.4928e-04\n",
      "Epoch 98/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.1844e-05 - val_loss: 5.4856e-04\n",
      "Epoch 99/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.0444e-05 - val_loss: 5.4308e-04\n",
      "Epoch 100/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.9393e-05 - val_loss: 5.3873e-04\n",
      "Epoch 101/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 6.2057e-05 - val_loss: 6.8660e-04\n",
      "Epoch 102/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.0165e-05 - val_loss: 5.1127e-04\n",
      "Epoch 103/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.8606e-05 - val_loss: 5.2725e-04\n",
      "Epoch 104/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.8122e-05 - val_loss: 5.0151e-04\n",
      "Epoch 105/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.9017e-05 - val_loss: 5.8121e-04\n",
      "Epoch 106/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.9796e-05 - val_loss: 7.2860e-04\n",
      "Epoch 107/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.6228e-05 - val_loss: 7.7541e-04\n",
      "Epoch 108/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.2920e-05 - val_loss: 4.8675e-04\n",
      "Epoch 109/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.8485e-05 - val_loss: 4.9127e-04\n",
      "Epoch 110/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.8539e-05 - val_loss: 5.6449e-04\n",
      "Epoch 111/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 5.6824e-05 - val_loss: 5.2411e-04\n",
      "Epoch 112/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.6984e-05 - val_loss: 5.0263e-04\n",
      "Epoch 113/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.8186e-05 - val_loss: 5.5192e-04\n",
      "Epoch 114/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.1752e-05 - val_loss: 5.3486e-04\n",
      "Epoch 115/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.7249e-05 - val_loss: 6.2497e-04\n",
      "Epoch 116/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.5507e-05 - val_loss: 4.8438e-04\n",
      "Epoch 117/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.7741e-05 - val_loss: 6.4649e-04\n",
      "Epoch 118/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.4820e-05 - val_loss: 4.7006e-04\n",
      "Epoch 119/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.5694e-05 - val_loss: 4.6596e-04\n",
      "Epoch 120/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.8363e-05 - val_loss: 4.7294e-04\n",
      "Epoch 121/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.3156e-05 - val_loss: 5.6256e-04\n",
      "Epoch 122/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.6066e-05 - val_loss: 5.0458e-04\n",
      "Epoch 123/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.4918e-05 - val_loss: 4.6793e-04\n",
      "Epoch 124/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.4287e-05 - val_loss: 5.3018e-04\n",
      "Epoch 125/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.4216e-05 - val_loss: 4.7329e-04\n",
      "Epoch 126/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.3402e-05 - val_loss: 4.8210e-04\n",
      "Epoch 127/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.7463e-05 - val_loss: 9.7536e-04\n",
      "Epoch 128/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.0777e-05 - val_loss: 6.0749e-04\n",
      "Epoch 129/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.0971e-05 - val_loss: 5.1086e-04\n",
      "Epoch 130/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.5668e-05 - val_loss: 5.1400e-04\n",
      "Epoch 131/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.3796e-05 - val_loss: 5.2829e-04\n",
      "Epoch 132/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.0413e-05 - val_loss: 5.2858e-04\n",
      "Epoch 133/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.3925e-05 - val_loss: 5.3532e-04\n",
      "Epoch 134/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.2148e-05 - val_loss: 5.0472e-04\n",
      "Epoch 135/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.0771e-05 - val_loss: 6.9499e-04\n",
      "Epoch 136/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.0379e-05 - val_loss: 5.4347e-04\n",
      "Epoch 137/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.4023e-05 - val_loss: 5.5110e-04\n",
      "Epoch 138/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.0356e-05 - val_loss: 5.9059e-04\n",
      "Epoch 139/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.5448e-05 - val_loss: 6.1218e-04\n",
      "Epoch 140/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.6972e-05 - val_loss: 5.5085e-04\n",
      "Epoch 141/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.3149e-05 - val_loss: 7.0357e-04\n",
      "Epoch 142/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.3036e-05 - val_loss: 9.9537e-04\n",
      "Epoch 143/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.2081e-05 - val_loss: 6.2936e-04\n",
      "Epoch 144/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.3845e-05 - val_loss: 6.6811e-04\n",
      "Epoch 145/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.6655e-05 - val_loss: 0.0012\n",
      "Epoch 146/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.0608e-05 - val_loss: 7.2141e-04\n",
      "Epoch 147/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 3.7424e-05 - val_loss: 9.3082e-04\n",
      "Epoch 148/500\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 4.0807e-05 - val_loss: 8.1404e-04\n",
      "Epoch 149/500\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 3.8615e-05 - val_loss: 6.8239e-04\n",
      "Epoch 149: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Validation set needs to be in a tuple with x , y\n",
    "\n",
    "history = model.fit(xrp_train[0] , xrp_train[1] , validation_data = xrp_val  , batch_size = 512  , epochs =500 , verbose = 1 , callbacks=[earlyStopping])\n",
    "num_epochs = earlyStopping.stopped_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f3f3fcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.ylim([0,0.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed9943",
   "metadata": {},
   "source": [
    "<Strong> Testing our model on the validation data once again , hyper-parameter adjustment. <Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2310c51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03318034789095613"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_predict = model.predict(eth_val[0])\n",
    "validation_predict = scaler.inverse_transform(validation_predict)\n",
    "\n",
    "validation_actual = scaler.inverse_transform(eth_val[1])\n",
    "mean_absolute_error(validation_actual , validation_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42689051",
   "metadata": {},
   "source": [
    "<Strong> Combining the train and validation set when perfected hyper-parameters and training on fresh model. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "74c49866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/148\n",
      "69/69 [==============================] - 3s 7ms/step - loss: 7.1433e-04\n",
      "Epoch 2/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 2.7368e-04\n",
      "Epoch 3/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 2.3545e-04\n",
      "Epoch 4/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 2.1483e-04\n",
      "Epoch 5/148\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 2.0654e-04\n",
      "Epoch 6/148\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 1.7975e-04\n",
      "Epoch 7/148\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 1.9449e-04\n",
      "Epoch 8/148\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 1.7719e-04\n",
      "Epoch 9/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.8784e-04\n",
      "Epoch 10/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.9803e-04\n",
      "Epoch 11/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.9986e-04\n",
      "Epoch 12/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.7793e-04\n",
      "Epoch 13/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 2.2024e-04\n",
      "Epoch 14/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.7300e-04\n",
      "Epoch 15/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.7122e-04\n",
      "Epoch 16/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.7212e-04\n",
      "Epoch 17/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.7573e-04\n",
      "Epoch 18/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6405e-04\n",
      "Epoch 19/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6002e-04\n",
      "Epoch 20/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.7762e-04\n",
      "Epoch 21/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.8775e-04\n",
      "Epoch 22/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6715e-04\n",
      "Epoch 23/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5483e-04\n",
      "Epoch 24/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6563e-04\n",
      "Epoch 25/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 2.0078e-04\n",
      "Epoch 26/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5775e-04\n",
      "Epoch 27/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5551e-04\n",
      "Epoch 28/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5436e-04\n",
      "Epoch 29/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6267e-04\n",
      "Epoch 30/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6170e-04\n",
      "Epoch 31/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.7301e-04\n",
      "Epoch 32/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5590e-04\n",
      "Epoch 33/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.8445e-04\n",
      "Epoch 34/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6698e-04\n",
      "Epoch 35/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5099e-04\n",
      "Epoch 36/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6867e-04\n",
      "Epoch 37/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6356e-04\n",
      "Epoch 38/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5406e-04\n",
      "Epoch 39/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.7804e-04\n",
      "Epoch 40/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4642e-04\n",
      "Epoch 41/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6848e-04\n",
      "Epoch 42/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.8806e-04\n",
      "Epoch 43/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6456e-04\n",
      "Epoch 44/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4467e-04\n",
      "Epoch 45/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5951e-04\n",
      "Epoch 46/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6214e-04\n",
      "Epoch 47/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5530e-04\n",
      "Epoch 48/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6137e-04\n",
      "Epoch 49/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4673e-04\n",
      "Epoch 50/148\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 1.5438e-04\n",
      "Epoch 51/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6098e-04\n",
      "Epoch 52/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4536e-04\n",
      "Epoch 53/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4222e-04\n",
      "Epoch 54/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5078e-04\n",
      "Epoch 55/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4929e-04\n",
      "Epoch 56/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6627e-04\n",
      "Epoch 57/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4858e-04\n",
      "Epoch 58/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4851e-04\n",
      "Epoch 59/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.7082e-04\n",
      "Epoch 60/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4778e-04\n",
      "Epoch 61/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3867e-04\n",
      "Epoch 62/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4542e-04\n",
      "Epoch 63/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5179e-04\n",
      "Epoch 64/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6695e-04\n",
      "Epoch 65/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3839e-04\n",
      "Epoch 66/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5159e-04\n",
      "Epoch 67/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5020e-04\n",
      "Epoch 68/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5616e-04\n",
      "Epoch 69/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5038e-04\n",
      "Epoch 70/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5702e-04\n",
      "Epoch 71/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4407e-04\n",
      "Epoch 72/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3856e-04\n",
      "Epoch 73/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6051e-04\n",
      "Epoch 74/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4923e-04\n",
      "Epoch 75/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5534e-04\n",
      "Epoch 76/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5429e-04\n",
      "Epoch 77/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4466e-04\n",
      "Epoch 78/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5595e-04\n",
      "Epoch 79/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3809e-04\n",
      "Epoch 80/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4368e-04\n",
      "Epoch 81/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4863e-04\n",
      "Epoch 82/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4368e-04\n",
      "Epoch 83/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3581e-04\n",
      "Epoch 84/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3762e-04\n",
      "Epoch 85/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3458e-04\n",
      "Epoch 86/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3531e-04\n",
      "Epoch 87/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4376e-04\n",
      "Epoch 88/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3621e-04\n",
      "Epoch 89/148\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 1.3766e-04\n",
      "Epoch 90/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4176e-04\n",
      "Epoch 91/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4448e-04\n",
      "Epoch 92/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6054e-04\n",
      "Epoch 93/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5066e-04\n",
      "Epoch 94/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4120e-04\n",
      "Epoch 95/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4154e-04\n",
      "Epoch 96/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3767e-04\n",
      "Epoch 97/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5286e-04\n",
      "Epoch 98/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4874e-04\n",
      "Epoch 99/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5205e-04\n",
      "Epoch 100/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3879e-04\n",
      "Epoch 101/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3415e-04\n",
      "Epoch 102/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3835e-04\n",
      "Epoch 103/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4001e-04\n",
      "Epoch 104/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4614e-04\n",
      "Epoch 105/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4508e-04\n",
      "Epoch 106/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6595e-04\n",
      "Epoch 107/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5288e-04\n",
      "Epoch 108/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3345e-04\n",
      "Epoch 109/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4408e-04\n",
      "Epoch 110/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4508e-04\n",
      "Epoch 111/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3252e-04\n",
      "Epoch 112/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.2580e-04\n",
      "Epoch 113/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3884e-04\n",
      "Epoch 114/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3840e-04\n",
      "Epoch 115/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4084e-04\n",
      "Epoch 116/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3989e-04\n",
      "Epoch 117/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5278e-04\n",
      "Epoch 118/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.6805e-04\n",
      "Epoch 119/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3923e-04\n",
      "Epoch 120/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4262e-04\n",
      "Epoch 121/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4351e-04\n",
      "Epoch 122/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3877e-04\n",
      "Epoch 123/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.2802e-04\n",
      "Epoch 124/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4673e-04\n",
      "Epoch 125/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4364e-04\n",
      "Epoch 126/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4508e-04\n",
      "Epoch 127/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4820e-04\n",
      "Epoch 128/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3661e-04\n",
      "Epoch 129/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3160e-04\n",
      "Epoch 130/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3279e-04\n",
      "Epoch 131/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3837e-04\n",
      "Epoch 132/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.5847e-04\n",
      "Epoch 133/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.2688e-04\n",
      "Epoch 134/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4558e-04\n",
      "Epoch 135/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4097e-04\n",
      "Epoch 136/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3715e-04\n",
      "Epoch 137/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3632e-04\n",
      "Epoch 138/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4608e-04\n",
      "Epoch 139/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3815e-04\n",
      "Epoch 140/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4746e-04\n",
      "Epoch 141/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3296e-04\n",
      "Epoch 142/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3291e-04\n",
      "Epoch 143/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3212e-04\n",
      "Epoch 144/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3121e-04\n",
      "Epoch 145/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4041e-04\n",
      "Epoch 146/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4347e-04\n",
      "Epoch 147/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.3482e-04\n",
      "Epoch 148/148\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 1.4543e-04\n"
     ]
    }
   ],
   "source": [
    "train_and_val = np.concatenate([eth_train[0] , eth_val[0]] )\n",
    "train_and_val_targets = np.concatenate([eth_train[1] , eth_val[1] ])\n",
    "\n",
    "freshModel = tf.keras.Model(inputs=inputs, outputs= x)\n",
    "\n",
    "freshModel.compile(optimizer='adam' , loss = 'mse')\n",
    "final = freshModel.fit(train_and_val , train_and_val_targets , batch_size = 512  , epochs = num_epochs )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d890bada",
   "metadata": {},
   "source": [
    "<Strong> Finally testing on test set and grabbing evaluation metrics - 1 day </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "eb5fc8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = freshModel.predict(xrp_test[0])\n",
    "test_actual = xrp_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "74cb086b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007813678664971681\n",
      "0.008081451215370905\n",
      "0.01137312817105585\n",
      "0.00012934804439526418\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(test_actual , test_predict))\n",
    "print(mean_absolute_percentage_error(test_actual , test_predict))\n",
    "print(mean_squared_error(test_actual , test_predict , squared = False))\n",
    "print(mean_squared_error(test_actual , test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce705440",
   "metadata": {},
   "source": [
    "<Strong> For Predicting more than 1 day in the future - Test Set. </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "15d3e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steps_in_future(hours_in_future , data):\n",
    "    \n",
    "    #All the hours_in_future time predictions\n",
    "    predictions = []\n",
    "    \n",
    "    # Have to cut off the (hours_in_future - 1) off the test set to avoid out of bounds error\n",
    "    test_data = data[0][:-(hours_in_future - 1)]\n",
    "    \n",
    "    for x in range (len(test_data)):\n",
    "        #Going through all the windows\n",
    "        last_window = test_data[x].reshape(1,-1)\n",
    "    \n",
    "            # Make as many predictions as hours_in_future\n",
    "        for i in range(hours_in_future):\n",
    "            \n",
    "            # Take the predicted value from the last window in training set\n",
    "            last_prediction = model.predict(last_window)[0]\n",
    "\n",
    "            #shifting the window size one step down\n",
    "            last_window[0] = np.roll(last_window[0], -1)\n",
    "\n",
    "            #replacing the old value with new prediction\n",
    "            last_window[0 , (len(last_window[0]) - 1)] = last_prediction\n",
    "\n",
    "        #append prediction\n",
    "        predictions.append(last_prediction)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d731a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_day_predictions = steps_in_future(3, xrp_test)\n",
    "five_day_predictions = steps_in_future(5, xrp_test)\n",
    "seven_day_predictions = steps_in_future( 7, xrp_test)\n",
    "nine_day_predictions = steps_in_future( 9, xrp_test)\n",
    "eleven_day_predictions = steps_in_future( 11, xrp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "cf328973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets to compare  \n",
    "\n",
    "targets_in_future_three = xrp_test[1][(3 - 1):]\n",
    "targets_in_future_five = xrp_test[1][(5 - 1):]\n",
    "targets_in_future_seven = xrp_test[1][(7 - 1):]\n",
    "targets_in_future_nine = xrp_test[1][(9 - 1):]\n",
    "targets_in_future_eleven = xrp_test[1][(11 - 1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ff5d48c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(num_days , actual , results):\n",
    "    \n",
    "    mae = mean_absolute_error(actual , results)\n",
    "    mse = mean_squared_error(actual , results )\n",
    "    rmse = mean_squared_error(actual , results , squared = False)\n",
    "    mape = mean_absolute_percentage_error(actual , results)\n",
    "\n",
    "    print(num_days , \"MAE :\" , mae ,\"MSE :\" , mse , \"RMSE :\" , rmse , \"MAPE :\" , mape)\n",
    "\n",
    "    return mae , mse , rmse , mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9c2d6b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three Hour Forecast MAE : 0.015079399265392313 MSE : 0.000434381052448295 RMSE : 0.020841810200850956 MAPE : 0.015905107998967945\n",
      "Five Hour Forecast MAE : 0.026097235767230567 MSE : 0.0010758355643167114 RMSE : 0.032799932382807005 MAPE : 0.028375448598149035\n",
      "Seven Hour Forecast MAE : 0.04034575851105517 MSE : 0.0023370811419944327 RMSE : 0.048343367094095056 MAPE : 0.0447967721422602\n",
      "Nine Hour Forecast MAE : 0.05783236834919574 MSE : 0.004600649619664693 RMSE : 0.06782808872189082 MAPE : 0.06553985285508362\n",
      "Eleven Hour Forecast MAE : 0.07925021456249269 MSE : 0.008432318591587648 RMSE : 0.09182765700804768 MAPE : 0.09127703906570565\n"
     ]
    }
   ],
   "source": [
    "three_days_mae , three_days_mse , three_days_rmse , three_days_mape = get_eval_metrics(\"Three Hour Forecast\" , targets_in_future_three , three_day_predictions)\n",
    "five_days_mae , five_days_mse , five_days_rmse , five_days_mape = get_eval_metrics(\"Five Hour Forecast\" , targets_in_future_five , five_day_predictions)\n",
    "seven_days_mae , seven_days_mse , seven_days_rmse , seven_days_mape = get_eval_metrics(\"Seven Hour Forecast\" , targets_in_future_seven , seven_day_predictions)\n",
    "nine_days_mae , nine_days_mse , nine_days_rmse , nine_days_mape = get_eval_metrics(\"Nine Hour Forecast\" , targets_in_future_nine , nine_day_predictions)\n",
    "eleven_days_mae , eleven_days_mse , eleven_days_rmse , eleven_days_mape = get_eval_metrics(\"Eleven Hour Forecast\" , targets_in_future_eleven , eleven_day_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4ba8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179310d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946bfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
